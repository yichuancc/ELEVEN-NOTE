# 一

1、自我介绍

2、介绍一下你在项目中使用的技术，技术解决了什么难题

## 3、说一下你对springcloud的理解

构建分布式系统不仅复杂而且容易出错，SpringCloud为常见的分布式系统模式提供了一种简单且易于接受的编程模型，帮助开发人员构建有弹性的、可靠的、协调的应用程序。SpringCloud构建于Springboot之上，使得开发人员很容易入手并快速应用于生产中。

我所理解的springcloud就是微服务系统架构的一站式解决方案，在平时我们构建微服务的过程中需要做如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等操作。而springcloud为我们提供了一套简易的编程模型，我们能在springboot的基础上轻松实现微服务项目的搭建。

## 4、说一下你对微服务的理解

我觉得微服务没有一个标准统一的概念，个人理解：微服务是一种可以让软件职责单一、松耦合、自包含、可以独立运行和部署的架构思想。 
关键思想：拆分、单一、独立、组件化。把原本一个庞大、复杂的项目按业务边界拆分一个一个独立运行的小项目，通过接口的方式组装成一个大的项目。 

## 5、mysql常用的优化有哪些，不是规范这些

```shell
我觉得将优化分为是两大类，软优化和硬优化。https://www.cnblogs.com/myseries/p/10735181.html
软优化包括：
	1、查询语句优化
		使用explain或desc分析一天语句的执行计划信息。
	2、优化子查询
		尽量使用join来代替子查询，因为子查询需要嵌套查询，
		嵌套查询时会创建一张临时表，临时表的建立和删除都会有较大的系统开销,
		而连接查询不会创建临时表,因此效率比嵌套子查询高。
	3、使用索引
		索引是提高查询速度最重要的方法之一，但是使用索引需要避免几个注意事项。
		1）like关键字匹配%开头的字符串，索引会失效
		2）or关键字的两个字段都用了索引，索引才会生效
		3）使用多列索引需要满足最左匹配
	4、分解表
		对应字段比较多的表，如果某些字段使用的频率很低的话，可以将其分离出来，形成新的表。
	5、增加中间表
		对于有大量连接查询的表可以创建中间表，从而减少在查询是造成的连接耗时。
	6、增加冗余字段
		类似于创建中间表，增加冗余字段也是减少连接查询耗时。
	7、分析表、检测表、优化表
		分析表主要是分析表中关键字的分布，检查表是检查表中是否存在错误，优化表主要是消除删除或更新造成的表空间浪费。
		1）分析表：使用analyze 关键字，analyze table 表名
		2）检查表: 使用 CHECK关键字,如CHECK TABLE user [option]
		3）优化表:使用OPTIMIZE关键字,如OPTIMIZE [LOCAL|NO_WRITE_TO_BINLOG] TABLE user;
硬优化包括：
	1、提升硬件（cpu、内存、磁盘）
		配置多核心和频率高的cpu
		配置大内存，提高内存，可以提高缓存区的容器，减少磁盘I/O时间，从而提高响应速度
		配置高速磁盘或合理分布磁盘，高速磁盘提高I/O,分布磁盘能提高并行操作的能力.
	2、mysql的参数设置
		优化数据库参数可以提供资源的利用率，提高服务器上面的mysql性能，mysql服务的配置参数在my.cnf或者my.ini，常用的几个性能影响较大的几个参数有
		key_buffer_size:索引缓存区的大小
		table_cache:能同时打开表的个数
		query_cache_size和query_cache_type
			query_cache_size是查询缓存区的大小，
			query_cache_type是查询缓存区的开关，0表示不使用缓冲区，1表示使用缓冲区。
		sort_buffer_size:排序缓冲区大小
	3、分库分表 + 读写分离
		也就是把一个库拆分为多个库，部署在多个数据库服务上，这时作为主库承载写入请求。
		然后每个主库都挂载至少一个从库，由从库来承载读请求
```

## 6、mysql为什么用于中小型数据项目，他的内部原理是怎么样的

```shell
Mysql 主要分为Server层和引擎层，
	server层主要包括连接器、查询缓存、分析器、优化器、执行器，同时是有一个日志模块（binlog）这个日志模块所有执行引擎可以共用，redolog只有InnoDB有。
	引擎层是插件式的，目前主要包括，MyISAM,InnoDB,memory等
	查询语句执行流程是：权限校验（如果命中缓存）-->查询缓存-->分析器-->优化器-->权限校验-->执行器-->引擎
	更新语句执行流程是：分析器-->权限校验-->执行器-->引擎-->redolog(prepare状态)-->binlog-->redolog(commit状态)
```

7、谈一下你对平时生活的思考

# 二

## 1、JVM对垃圾回收的认识

```shell
#https://www.cnblogs.com/czwbig/p/11127159.html
和JavaGuide

Java的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java自动内存管理最核心的功能是堆内存中的分配和回收。

#HotSpot为什么要分为新生代和老年代
	从垃圾回收的角度，由于现在收集器都是采用分代垃圾收集算法，Java堆，还可以细分为：新生代和老年代，在细致一点有：Eden区、From survivor、To Survivor空间等，"进一步划分的目的是更好的回收内存，或者说更快的分配内存"。

	关于Java堆，新生代、老年代、Eden空间、From survivor空间，To survivor空间，java进程运行过程中创建的对象存放在堆中，
	堆被划分成两个不同的区域：新生代（Young）老年代（old）。
	新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。
	
默认：https://blog.csdn.net/pp_lan/article/details/104674632
	新生代与老年代比值是1:2。该值可以通过参数 –XX:NewRatio 来指定
	Eden：from：to = 8 : 1 : 1 。可以通过参数 –XX:SurvivorRatio 来设定 
	"JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。 因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间"。

#内存的分配与回收
	1、对象优先在eden分配。
		大多数情况下，对象在新生代eden分配，当eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。
	2、大对象直接进入老年代
		大对象就是需要连续内存空间的对象（比如：字符串、数组）。
		虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，大于这个设置值的对象直接在老年代分配。"这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。"
	3、长期存活的对象将进入老年代
		虚拟机就给每个对象一个对象年龄age计数器。
		对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。可以通过-XX:MaxTenuringThreshold 来设置。
		默认晋升年龄并不都是 15，这个是要区分垃圾收集器的，CMS 就是 6
	4、动态对象年龄判定
		为了能更好地适应不同程序的内存状况，无须等到 MaxTenuringThreshold 中要求的年龄，同年对象达到 Survivor 空间的一半后（默认50%，可以通过参数设置），他们以及年龄大于他们的对象都将直接进入老年代。。
		
#Minor GC 和Full GC的区别
	Minor是新生代垃圾收集：Minor GC 非常频繁，一般回收速度也比较快。
	Full GC是怎么理解，可以说是老年代收集Major GC，也可以说是整堆收集Full GC。
	Full GC是整个堆进行垃圾收集。
	Major GC 的速度一般会比 Minor GC 慢 10 倍以上。
	
	5、主要的进行的GC区域
		针对HotSpot VM的实现，GC准确的是两大类
		部分收集 partial gc
			新生代收集（Minor GC/Young GC):只对新生代进行垃圾收集
			老年代收集（Major GC/Old GC):只对老年代进行收集。
			混合收集（Mixed GC): 对整个新生代和部分老年代进行垃圾收集
		整堆收集 full gc
	6、空间分配担保
		空间分配担保是为了确保Minor GC之前，老年代本身还有空余空间可以容纳新生代的对象。大于说明Minor GC是安全的。
		只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行 Minor GC ，否则将进行 Full GC。
		
#怎么判断对象已经死亡
引用计数法  和  可达性分析算法
	1、引用计数法，简单，效率高。但是无法解决对象相互循环引用的问题，目前主流的虚拟机没有采用这个。
	2、可达性分析算法，通过一系列称为GC Roots的对象作为起点，从这些节点开始向下搜索，搜索的路径称为引用链。当一个对象没有任何引用链相连的话，此对象可以被回收。

#那些对象可以作为GC Roots呢
	虚拟机栈（栈帧中的本地变量表）中引用的对象
	本地方法栈（native)中引用的对象
	方法区中静态属性引用的对象
	方法区中常量引用的对象
	所以被同步锁持有的对象
	
#对象可以被回收，就代表一定会被回收吗？
	要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记只是进行一次筛选。

#永久代的垃圾收集主要回收两部分内容
	废弃常量和无用的类。
#如何判断一个常量是废弃常量
	运行时常量池主要回收废弃常量，当然没有任务对象引用这个常量，这个常量就是废弃常量。
#如何判断一个类是无用的类
	方法区主要回收无用类，该类所有的实例都已经被回收，加载该类的classLoaer已经被回收，该类对应的class对象没有被任何地方应用。满足这三个条件，就是一个无用的类。
	
#垃圾收集算法
	1、标记-清除算法
		“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。
		不足：
			1）标记和清除过程效率都不高。
			2）标记清除之后会产生大量不连续的内存碎片，占用空间问题。
	2、标记-复制算法
		将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。
		不足：
        	内存缩小为原来的一半。
        	存活对象比较多，大量的复制操作，效率很低。
	3、标记-整理算法
		过程仍然与“标记-清除”算法一样，后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。
	4、分代收集算法
		根据对象存活周期的不同将内存划分为几块并采用不用的垃圾收集算法。大量对象都是朝生夕死，新生代对象少量存活，就用标记-复制算法。老年代对象存活率高、没有额外空间对它进行分配担保。就用标记-清除或者标记-整理。
		
#垃圾收集器
	1、Serial收集器，这是一个单线程的收集器。新生代标记-复制，老年代标记-整理
	2、ParNew收集器， Serial 收集器的多线程版本，多线程标记复制。新生代采用标记-复制算法，老年代采用标记-整理算法。
	3、Parallel Scavenge收集器，几乎和 ParNew 都一样，，多线程标记复制。关注点是吞吐量，吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。新生代采用标记-复制算法，老年代采用标记-整理算法。这是 JDK1.8 默认收集器
	4、Serial Old 收集器，Serial 收集器的老年代版本
	5、Parallel Old 收集器，Parallel Scavenge 收集器的老年代版本。
	6、CMS 收集器，收集器是一种以获取最短回收停顿时间为目标的收集器。CMS 收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤。
		1）初始标记
		2）并发标记
		3）重新标记
		4）并发清除
		初始标记、重新标记这两个步骤仍然需要"Stop The World"，耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作。
	
		初始标记：暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快。
		并发标记：同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。
		重新标记：阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些。
		并发清除：开启用户线程，同时 GC 线程开始对未标记的区域做清扫。
		
		CMS优点：并发收集、低停顿
		CMS缺点：
		"导致吞吐量降低"：在并发阶段，虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。
		"无法处理浮动垃圾"：由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉。这一部分垃圾就称为“浮动垃圾”
		"会产生大量空间碎片"：使用的回收算法-“标记-清除”.
	7、G1收集器
		特点
    		"并行与并发"、"分代收集"、"空间整合",“标记-整理”算法实现的收集器、"可预测的停顿"，让使用者明确指定在一个时间片段内停顿。
		步骤：
			1）初始标记
			2）并发标记
			3）最终标记
			4）筛选标记
		使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region （不需要连续）的集合。G1 在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是Garbage-First名称的来由），保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。
#阅读GC日志
	可以得到GC前的内存容量，GC后的内存容量，GC前的堆使用容量，GC后堆使用容量。GC 所占用的时间。
```

## 2、对JUC的认识

```shell
JUC是指java.util.concurrent包。里面的工具类可以很方便的实现多线程的开发。

#1、并发容器
	ConcurrentHashMap : 线程安全的 HashMap	
	CopyOnWriteArrayList : 线程安全的 List，在读多写少的场合性能非常好。
	ConcurrentLinkedQueue : 高效的并发队列，使用链表实现。可以看做线程安全的 LinkedList，是非阻塞队列。
	BlockingQueue : 这是一个接口，通过链表、数组等方式实现，是阻塞队列。
	ConcurrentSkipListMap : 跳表的实现。使用跳表的数据结构进行快速查找。
	
#1、1ConcurrentHashMap怎么实现线程安全的
参考：https://blog.csdn.net/liyuanbo1997/article/details/107580664
1.7：使用的分段锁，每一个 Segment 上同时只有一个线程可以操作，每一个 Segment 都是一个类似 HashMap 数组的结构。put操作采用自旋锁。
1.8：使用CAS + Synchronized来保证安全性。
	put操作：
		1、先判断key和value是否为空，为空抛出异常
		2、计算出hash值，遍历表结构
			1）是否需要初始化表，initTable()。
			2）或者table[i]节点，空则用CAS插入。
			3）看是否有线程正在扩容，有帮助扩容。
			4）synchronized获取锁资源，判断是链表节点还是红黑树节点，插入。
		3、统计节点树
		4、返回空
	initTable():初始化是通过自旋和 CAS 操作完成的.
	get操作：
		1、计算出hash值
		2、查找指定位置，如果头节点就是要找的，返回value
		3、如果头节点hash小于0，说明正在扩容或者是红黑树，find查找
		4、如果是链表，遍历查找。
	CAS：乐观锁策略，操作流程就是线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程。
	
#1、2CopyOnWriteArrayList怎么实现现场安全的
	"通过拷贝新数组实现"
	对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了.
	get操作：
		读取操作没有任何同步控制和锁操作，内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。
	add操作：
		//源码：拷贝新数组
		Object[] newElements = Arrays.copyOf(elements, len + 1);
		add()方法在添加集合的时候加了锁（用的ReentrantLock），保证了同步，避免了多线程写的时候会 copy 出多个副本出来。
		
#ConcurrentLinkedQueue和BlockingQueue
Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue， 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。

#2、阻塞队列blcokingQueue
常用的阻塞队列，见下面的BlockingQueue

#3、线程池
见下面的线程池
	
#4、AQS源码和常用同步组件类
见下面的AQS介绍1、2、3

#5、原子类
原子类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

基本类型
AtomicInteger：整型原子类
AtomicLong：长整型原子类
AtomicBoolean ：布尔型原子类

数组类型
AtomicIntegerArray：整型数组原子类
AtomicLongArray：长整型数组原子类
AtomicReferenceArray ：引用类型数组原子类

引用类型
AtomicReference：引用类型原子类
AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。
AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。
```

# BlcokingQueue

> https://javadoop.com/

描述：BlockingQueue 是一个**先进先出**的队列（Queue），BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。

>  BlockingQueue，关注点在 put(e) 和 take() 这两个方法，这两个方法是带阻塞的。

## ArrayBlockingQueue

ArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。

其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。

ArrayBolckingQueue实现并发的原理是，读操作和写操作都是获取到AQS独占锁才能操作。如果队列为空，读操作的线程进入到**读线程队列**排队，等待写线程写入新的元素，然后唤醒读线程队列的第一个等待线程。如果队列已满，写操作的线程进入到**写线程队列**排队，等待读线程将队列元素移除腾出空间，然后唤醒写线程队列的第一个等待线程。

ArrrayBolockingQueue就是运用了AQS中Condition的使用，条件队列转移到阻塞队列。

## LinkedBlockingQueue

底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用。

源码类属性：

```java
// 队列容量
private final int capacity;

// 队列中的元素数量
private final AtomicInteger count = new AtomicInteger(0);

// 队头
private transient Node<E> head;

// 队尾
private transient Node<E> last;

// take, poll, peek 等读操作的方法需要获取到这个锁
private final ReentrantLock takeLock = new ReentrantLock();

// 如果读操作的时候队列是空的，那么等待 notEmpty 条件
private final Condition notEmpty = takeLock.newCondition();

// put, offer 等写操作的方法需要获取到这个锁
private final ReentrantLock putLock = new ReentrantLock();

// 如果写操作的时候队列是满的，那么等待 notFull 条件
private final Condition notFull = putLock.newCondition();
```

这里用了两个锁，两个 Condition

**takeLock 和 notEmpty 搭配：**如果要获取（take）一个元素，需要获取 takeLock 锁，但是获取了锁还不够，如果队列此时为空，还需要队列notEmpty (不为空）这个条件（Condition）。

**putLock 需要和 notFull 搭配：**如果要插入（put）一个元素，需要获取 putLock 锁，但是获取了锁还不够，如果队列此时已满，还需要队列notFull(不是满的）这个条件（Condition）。

```java
// 必须要获取到 putLock 才可以进行插入操作

// 必须要获取到 takeLock 才可以进行出队操作
```

写操作，写操作有各自的条件队列，读操作是排好队的，写操作也是排好队的，唯一的并发问题在于一个写操作和一个读操作同时进行，只要控制好这个就可以了。

## SynchronousQueue

Synchronous 指的就是读线程和写线程需要同步， SynchronousQueue 的队列其实是虚的，其不提供任何空间（一个都没有）来存储元素。数据必须从某个写线程交给某个读线程，而不是写到某个队列中等待被消费。

## PriorityBlockingQueue

带排序的 BlockingQueue 实现，其并发控制采用的是 ReentrantLock，队列为无界队列，只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容

## 总结

ArrayBlockingQueue 底层是数组，有界队列，如果我们要使用生产者-消费者模式，这是非常好的选择。

LinkedBlockingQueue 底层是链表，可以当做无界和有界队列来使用，所以大家不要以为它就是无界队列。

SynchronousQueue 本身不带有空间来存储任何元素，使用上可以选择公平模式和非公平模式。

PriorityBlockingQueue 是无界队列，基于数组，数据结构为二叉堆，数组第一个也是树的根节点总是最小值。

# 线程池

> https://javadoop.com/post/java-thread-pool

使用线程池好处：

1、**降低资源消耗**

2、**提高响应速度**

3、**提高线程的可管理性**

## Executor 接口

Executor接口，位于最顶层，就一个 execute(Runnable runnable) 接口方法定义。

ExecutorService 也是接口，继承Executor，添加了很多方法。

AbstractExecutorService抽象类，实现ExecutorService 接口。

ThreadPoolExecutor类，继承AbstractExecutorService抽象类。这是一个重点类。

其他类：

​	Executors 类，类名中带字母 s，这个是工具类，里面的方法都是静态方法。

​	线程池支持**获取线程执行的结果**，引入Future 接口，RunnableFuture 继承Future ，我们需要关心实现类 FutureTask。

​	使用线程池，提交的每个任务是实现了 Runnable 接口的，就是先将 Runnable 的任务包装成 FutureTask，然后再提交到线程池。这样，比较容易记住 FutureTask 这个类名：它首先是一个任务（Task），具有 Future 接口，可以在（Future）得到执行的结果。

​	线程池中的 BlockingQueue ，线程数达到 corePoolSize，任务就会提交到等待队列中，等线程池中的线程来取任务去执行。

## ExecutorService接口

继承自 `Executor` 接口的 `ExecutorService` 接口，这个接口提供了比较丰富的功能，也是我们最常使用到的接口

一般我们定义一个线程池的时候，往往都是使用这个接口：

```java
ExecutorService executor = Executors.newFixedThreadPool(args...);
ExecutorService executor = Executors.newCachedThreadPool(args...);
```

```java
public interface ExecutorService extends Executor {

    // 关闭线程池，已提交的任务继续执行，不接受继续提交新任务
    void shutdown();

    // 关闭线程池，尝试停止正在执行的所有任务，不接受继续提交新任务
    // 它和前面的方法相比，加了一个单词“now”，区别在于它会去停止当前正在进行的任务
    List<Runnable> shutdownNow();

    // 线程池是否已关闭
    boolean isShutdown();

    // 如果调用了 shutdown() 或 shutdownNow() 方法后，所有任务结束了，那么返回true
    // 这个方法必须在调用shutdown或shutdownNow方法之后调用才会返回true
    boolean isTerminated();

    // 等待所有任务完成，并设置超时时间
    // 我们这么理解，实际应用中是，先调用 shutdown 或 shutdownNow，
    // 然后再调这个方法等待所有的线程真正地完成，返回值意味着有没有超时
    boolean awaitTermination(long timeout, TimeUnit unit)
            throws InterruptedException;

    // 提交一个 Callable 任务
    <T> Future<T> submit(Callable<T> task);

    // 提交一个 Runnable 任务，第二个参数将会放到 Future 中，作为返回值，
    // 因为 Runnable 的 run 方法本身并不返回任何东西
    <T> Future<T> submit(Runnable task, T result);

    // 提交一个 Runnable 任务
    Future<?> submit(Runnable task);

    // 执行所有任务，返回 Future 类型的一个 list
    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)
            throws InterruptedException;

    // 也是执行所有任务，但是这里设置了超时时间
    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,
                                  long timeout, TimeUnit unit)
            throws InterruptedException;

    // 只有其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果
    <T> T invokeAny(Collection<? extends Callable<T>> tasks)
            throws InterruptedException, ExecutionException;

    // 同上一个方法，只有其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果，
    // 不过这个带超时，超过指定的时间，抛出 TimeoutException 异常
    <T> T invokeAny(Collection<? extends Callable<T>> tasks,
                    long timeout, TimeUnit unit)
            throws InterruptedException, ExecutionException, TimeoutException;
}
```

这些方法都很好理解，一个简单的线程池主要就是这些功能，能提交任务，能获取结果，能关闭线程池，这也是为什么我们经常用这个接口的原因

## AbstractExecutorService类

需要获取结果（FutureTask），用 submit 方法，不需要获取结果，可以用 execute 方法。

部分源码

```java
public abstract class AbstractExecutorService implements ExecutorService {
	....
    // 提交任务
    public Future<?> submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        // 1. 将任务包装成 FutureTask
        RunnableFuture<Void> ftask = newTaskFor(task, null);
        // 2. 交给执行器执行，execute 方法由具体的子类来实现
        // 前面也说了，FutureTask 间接实现了Runnable 接口。
        execute(ftask);
        return ftask;
    }

    public <T> Future<T> submit(Runnable task, T result) {
        if (task == null) throw new NullPointerException();
        // 1. 将任务包装成 FutureTask
        RunnableFuture<T> ftask = newTaskFor(task, result);
        // 2. 交给执行器执行
        execute(ftask);
        return ftask;
    }

    public <T> Future<T> submit(Callable<T> task) {
        if (task == null) throw new NullPointerException();
        // 1. 将任务包装成 FutureTask
        RunnableFuture<T> ftask = newTaskFor(task);
        // 2. 交给执行器执行
        execute(ftask);
        return ftask;
    }
    .........
}

```

抽象类包装了一些基本的方法，可是像 submit、invokeAny、invokeAll 等方法，它们都没有真正开启线程来执行任务，它们都只是在方法内部调用了 execute 方法。最重要的 execute(Runnable runnable) 方法还没出现，需要等具体执行器来实现这个最重要的部分，这里我们要说的就是 ThreadPoolExecutor 类了。

## ThreadPoolExecutor类

我们经常使用`Executors` 这个工具类来快速构造一个线程池，几个常见的线程池；

**Executors.newFixedThreadPool()**:生成一个固定大小的线程池：

```java
 /**
  * 创建一个可重用固定数量线程的线程池
  */
public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>(),
                                      threadFactory);
}

```

**Executors.SingleThreadExecutor** :生成只有一个线程的线程池

```java
/**
 *返回只有一个线程的线程池
 */
public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>(),
                                    threadFactory));
}
```

**Executors.CachedThreadPool** ：生成一个需要的时候就创建新的线程

```java
/**
 * 创建一个线程池，根据需要创建新线程，但会在先前构建的线程可用时重用它。
 */
public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>(),
                                      threadFactory);
 }
```

它们最终都会导向这个构造方法：

```java
/**
 * 用给定的初始参数创建一个新的ThreadPoolExecutor。
 */
public ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量
                          int maximumPoolSize,//线程池的最大线程数
                          long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间
                           TimeUnit unit,//时间单位
                           BlockingQueue<Runnable> workQueue,//任务队列，用来储存等待执行任务的队列
                           ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可
                           RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务
                               ) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
    	// 这几个参数都是必须要有的
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }
```

**`ThreadPoolExecutor` 3 个最重要的参数：**

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中，BlockingQueue 接口的某个实现（常使用 ArrayBlockingQueue 和 LinkedBlockingQueue）

`ThreadPoolExecutor`其他常见参数 :

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

## 线程状态

```java
// 这里 COUNT_BITS 设置为 29(32-3)，意味着前三位用于存放线程状态，后29位用于存放线程数
// 很多初学者很喜欢在自己的代码中写很多 29 这种数字，或者某个特殊的字符串，然后分布在各个地方，这是非常糟糕的
private static final int COUNT_BITS = Integer.SIZE - 3;

// 000 11111111111111111111111111111
// 这里得到的是 29 个 1，也就是说线程池的最大线程数是 2^29-1=536870911
// 以我们现在计算机的实际情况，这个数量还是够用的
private static final int CAPACITY   = (1 << COUNT_BITS) - 1;

// 我们说了，线程池的状态存放在高 3 位中
// 运算结果为 111跟29个0：111 00000000000000000000000000000
private static final int RUNNING    = -1 << COUNT_BITS;
// 000 00000000000000000000000000000
private static final int SHUTDOWN   =  0 << COUNT_BITS;
// 001 00000000000000000000000000000
private static final int STOP       =  1 << COUNT_BITS;
// 010 00000000000000000000000000000
private static final int TIDYING    =  2 << COUNT_BITS;
// 011 00000000000000000000000000000
private static final int TERMINATED =  3 << COUNT_BITS;
```

在这里，介绍下线程池中的各个状态和状态变化的转换过程：

- RUNNING：最正常的状态：接受新的任务，处理等待队列中的任务
- SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务
- STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程
- TIDYING：所有的任务都销毁了，workCount 为 0。线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()
- TERMINATED：terminated() 方法结束后，线程池的状态就会变成这个

> RUNNING定义为-1，SHUTDOWN定义为0，其他的都比0大，所以等于0的时候不能提交任务，大于 0 的话，连正在执行的任务也需要中断。

状态转换有下面几种

- **RUNNING -> SHUTDOWN：当调用了 shutdown() 后，会发生这个状态转换，这也是最重要的**
- **(RUNNING or SHUTDOWN) -> STOP：当调用 shutdownNow() 后，会发生这个状态转换，这下要清楚 shutDown() 和 shutDownNow() 的区别了**
- SHUTDOWN -> TIDYING：当任务队列和线程池都清空后，会由 SHUTDOWN 转换为 TIDYING
- STOP -> TIDYING：当任务队列清空后，发生这个转换
- TIDYING -> TERMINATED：这个前面说了，当 terminated() 方法结束后

## execute ()方法

```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();

    // 前面说的那个表示 “线程池状态” 和 “线程数” 的整数
    int c = ctl.get();

    // 如果当前线程数少于核心线程数，那么直接添加一个 worker 来执行任务，
    // 创建一个新的线程，并把当前任务 command 作为这个线程的第一个任务(firstTask)
    if (workerCountOf(c) < corePoolSize) {
        // 添加任务成功，那么就结束了。提交任务嘛，线程池已经接受了这个任务，这个方法也就可以返回了
        // 至于执行的结果，到时候会包装到 FutureTask 中。
        // 返回 false 代表线程池不允许提交任务
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 到这里说明，要么当前线程数大于等于核心线程数，要么刚刚 addWorker 失败了

    // 如果线程池处于 RUNNING 状态，把这个任务添加到任务队列 workQueue 中
    if (isRunning(c) && workQueue.offer(command)) {
        /* 这里面说的是，如果任务进入了 workQueue，我们是否需要开启新的线程
         * 因为线程数在 [0, corePoolSize) 是无条件开启新的线程
         * 如果线程数已经大于等于 corePoolSize，那么将任务添加到队列中，然后进到这里
         */
        int recheck = ctl.get();
        // 如果线程池已不处于 RUNNING 状态，那么移除已经入队的这个任务，并且执行拒绝策略
        if (! isRunning(recheck) && remove(command))
            reject(command);
        // 如果线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程
        // 到这里，我们知道了，这块代码的真正意图是：担心任务提交到队列中了，但是线程都关闭了
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 如果 workQueue 队列满了，那么进入到这个分支
    // 以 maximumPoolSize 为界创建新的 worker，
    // 如果失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略
    else if (!addWorker(command, false))
        reject(command);
}
```

​	1、execute()方法

​	2、如果当前线程数少于核心线程数，就直接调用addWorker（）添加任务

​		1）addWorker（）方法

​		2）满足下面条件，不创建worker，1. 线程池状态大于 SHUTDOWN，其实也就是 STOP, TIDYING, 或 TERMINATED。2. firstTask != null。3. workQueue.isEmpty()

​		3）如果成功，就是创建线程前的条件校验都满足了，准备创建线程执行任务了

​		4）持有线程池的全局锁，关闭一个线程池需要这个锁，我持有锁的期间，线程池不会被关闭。添加线程，启动线程

​		5）如果没有启动，就清理一下addWorkerFailed（）；

​		6）启动调用run，run调用runWorker（），runWorker调用任务的run（）方法，执行任务；

​	3、如果当前线程数大于核心线程数，或者addWorker（）失败了，判断线程是否处于RUNNING状态，把这个任务添加到任务队列workQueue中。如果线程池已不处于 RUNNING 状态，那么移除已经入队的这个任务，并且执行拒绝策略。如果线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程。

​	4、如果 workQueue 队列满了，那么进入到这个分支。以 maximumPoolSize 为界创建新的 worker，如果失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略

​	拒绝策略4种：

​	**`ThreadPoolExecutor.AbortPolicy`** ：抛出 `RejectedExecutionException`来拒绝新任务的处理。默认策略。

​	**`ThreadPoolExecutor.CallerRunsPolicy`** ：调用执行自己的线程运行任务。

​	**`ThreadPoolExecutor.DiscardPolicy`** ：不处理新任务，直接丢弃掉。

​	**`ThreadPoolExecutor.DiscardOldestPolicy`** ： 此策略将丢弃最早的未处理的任务请求。

## 总结

说说线程池中的线程创建时机？

```shell
1. 如果当前线程数少于 corePoolSize，那么提交任务的时候创建一个新的线程，并由这个线程执行这个任务；
2. 如果当前线程数已经达到 corePoolSize，那么将提交的任务添加到队列中，等待线程池中的线程去队列中取任务；
3. 如果队列已满，那么创建新的线程来执行任务，需要保证池中的线程数不会超过 maximumPoolSize，如果此时线程数超过了 maximumPoolSize，那么执行拒绝策略。
```

任务执行过程中发生异常怎么处理？

```shell
如果某个任务执行出现异常，那么执行任务的线程会被关闭，而不是继续接收其他任务。然后会启动一个新的线程来代替它。
```

什么时候会执行拒绝策略？

```shell
1、workers 的数量达到了 corePoolSize（任务此时需要进入任务队列），任务入队成功，与此同时线程池被关闭了，而且关闭线程池并没有将这个任务出队，那么执行拒绝策略。"非常边界的问题，入队和关闭线程池并发执行"。execute 里第一个 reject(command) 。

2、workers 的数量大于等于 corePoolSize，将任务加入到任务队列，可是队列满了，任务入队失败，那么准备开启新的线程，可是线程数已经达到 maximumPoolSize，那么执行拒绝策略。 execute 里第一个 reject(command) 
```

# AQS介绍一 

> https://javadoop.com/

AQS的核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置成有效的工作线程。并将共享资源设置为多少锁定状态。如果请求的资源被占用，就用一套线程阻塞等待已经唤醒时锁分配机制。这个机制AQS是通过CLH队列锁失效的，就是将暂时没有获取到锁的线程加入队列中。

## 1、结构属性4个

head：头节点，当有持有锁的线程

tail：阻塞的尾节点，每个新的节点加入，都插入最后，形成一个链表

state：锁的状态

exclusiveOwnerThread ：当前独占锁的线程

```java
// 头结点，你直接把它当做 当前持有锁的线程 可能是最好理解的
private transient volatile Node head;

// 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个链表
private transient volatile Node tail;

// 这个是最重要的，代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁
// 这个值可以大于 1，是因为锁可以重入，每次重入都加上 1
private volatile int state;

// 代表当前持有独占锁的线程，举个最重要的使用例子，因为锁可以重入
// reentrantLock.lock()可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁
// if (currentThread == getExclusiveOwnerThread()) {state++}
private transient Thread exclusiveOwnerThread; //继承自AbstractOwnableSynchronizer
```

AbstractQueuedSynchronizer 的等待队列示意如下所示，注意了，之后分析过程中所说的 queue，也就是阻塞队列**不包含 head，不包含 head，不包含 head**。等待队列中每个线程被包装成一个 Node 实例，数据结构是链表。

## 2、Node的结构

thread + waitStatus + pre + next

```java
static final class Node {
	
    //中间还有代码。。。
    
    // 取值为上面的1、-1、-2、-3，或者0(以后会讲到)
    // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待，
    //    ps: 半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。
    volatile int waitStatus;
    // 前驱节点的引用
    volatile Node prev;
    // 后继节点的引用
    volatile Node next;
    // 这个就是线程本尊
    volatile Thread thread;

}
```

## 3、线程抢锁

公平锁：	

​	1、调用锁reentrantLock.lock（）

​	2、争锁acquire（）

​	3、尝试争锁 tryAcquire（），直接就成功，不需要进队列排队。没有成功就挂起，放到阻塞队列

​		1）判断此刻是否持有锁

​				看看有没有人等 && 没有就用CAS获取一下，成功就占用锁

​	4、tryAcquire 失败 执行 acquireQueued（addWaiter(Node.EXCLUSIVE), arg)）放到队列

​	5、addWaiter（）把当前线程包装成node，进入队列。队列不为空，用CAS把自己设置成队尾。如果队列是空，或者CAS失败(有线程在竞争入队)，执行enq（）；

​	6、enq（）只有两种情况，等待队列为空，或者CAS失败(有线程在竞争入队)。enq（）方法自旋，一直竞争排队，就是将当前线程排到队尾。

​	7、acquireQueued（）这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了。

​		1）p==head,当前节点进到了阻塞队列，是阻塞队列的第一个，前驱是head.

​			&& tryAcquire(arg)			

​			ps：阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列。

​		2）node不是头，或者tryAcquire（）没抢赢。就进入shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()

​	8、  shouldParkAfterFailedAcquire（）当前线程没有抢到锁，是否需要挂起当前线程

​			parkAndCheckInterrupt（）这个方法就是负责挂起线程的，调用9

​	9、LockSupport.park(this)来挂起线程

## 4、解锁操作

如果线程没获取到锁，线程会被 `LockSupport.park(this);` 挂起停止，等待被唤醒。

​	1、调用解锁reentrantLock.unlock（）

​	2、释放release（）

​	3、尝试释放tryRelease（），是否完全释放，有重入，就一步步释放。

​	4、成功后，就unparkSuccessor()唤醒后继节点。

​	5、唤醒线程LockSupport.unpark(s.thread);

## 总结

​	在并发环境中， 加锁和解锁需要是哪个部件的协调

​	1、锁状态： state 的作用，它为 0 的时候代表没有线程占有锁，可以去争抢这个锁，用 CAS 将 state 设为 1，如果 CAS 成功，说明抢到了锁。锁重入的话，state进行 +1 就可以，解锁就是减 1，直到 state 又变为 0，代表释放锁，所以 lock() 和 unlock() 必须要配对啊。

​	2、线程的阻塞和解除阻塞：AQS 中采用了 LockSupport.park(thread) 来挂起线程，用 unpark 来唤醒线程。

​	3、阻塞队列：只能有一个线程拿到锁，其他的线程等待，这个时候就需要一个queue来管理这些线程。AQS 用的是一个 FIFO 的队列，就是一个链表，每个 node 都持有后继节点的引用。AQS 采用了 CLH 锁的变体来实现。

​		CLH介绍：CLH是在前驱节点的属性上自旋，CLH的队列是隐式的，并不实际持有下一个节点，CLH锁释放时只需要改变自己的属性。

# AQS介绍二

> https://javadoop.com/

## 1、公平锁和非公平锁的不同

​	1、非公平锁在调用lock（）是，首先会调用CAS抢锁，如果正好锁没有被占用，就直接获取到锁返回。

​	2、非公平锁在CAS失败后，和公平锁一样，进入到tryAcquire（）方法，在方法中，如果发现锁被释放，直接CAS抢锁。公平锁是会判断是否有线程处于等待状态，有就继续等待。

​	公平锁和非公平锁就这两点区别，非公平锁如果两次CAS都失败，将和公平锁一样，都进入到阻塞队列等待唤醒。

## 2、condition介绍

​	condition 是依赖于 ReentrantLock  的，不管是调用 await 进入等待还是 signal 唤醒，**都必须获取到锁才能进行操作**。

```java
public class ConditionObject implements Condition, java.io.Serializable {
     	...
        // 条件队列的第一个节点
        // 不要管这里的关键字 transient，是不参与序列化的意思
        private transient Node firstWaiter;
        // 条件队列的最后一个节点
        private transient Node lastWaiter;
        ......
}
```

​	阻塞队列是双向链表队列，条件队列是单向链表队列。

​	引入条件队列概念：

​	每个condition有一个关联的条件队列，线程调用condition.await()将线程包装成Node后加入到条件队列，然后阻塞在这里。

​	调用condition.singal()触发唤醒，唤醒队头，将对应的条件队列firstWaiter（队头）移到阻塞队列队尾，等待获取锁。获取锁后singal方法才能返回，继续往下执行。

​	源码过程包括：

​	1、将节点加入到条件队列

​	2、完全释放独占锁：因为是可重入，所以是完全释放。这样其他线程才能持有锁。

​	3、等待进入阻塞队列：释放掉锁以后，会自旋，发现自己还没到阻塞队列，那么挂起，等待被转移到阻塞队列。 `LockSupport.park(this);`线程挂起

​	4、signal唤醒线程，转移到阻塞队列：刚刚到 `LockSupport.park(this);` 把线程挂起了，等待唤醒，唤醒操作通常由另一个线程来操作。

​	5、唤醒后检查中断状态：signal后，线程由条件队列转移到了阻塞队列，之后就准备获取锁了。线程唤醒后第一步是调用 checkInterruptWhileWaiting(node) 这个方法，判断是否在线程挂起期间发生了中断。

​	ps：即使发生了中断，节点依然会转移到阻塞队列。

​	while循环结束条件，要么中断，要么转移成功。while出来后，准备获取锁。

​	6、获取独占锁：while结束后，if (acquireQueued(node, savedState) && interruptMode != THROW_IE)。  acquireQueued 获取锁，注意前面不管有没有发生中断，都会进入到阻塞队列，而 acquireQueued(node, savedState) 的返回值就是代表线程是否被中断。返回 true，说明被中断了，而且 interruptMode != THROW_IE，说明在 signal 之前就发生中断了，这里将 interruptMode 设置为 REINTERRUPT，用于待会重新中断。

​	7、处理中断状态：interruptMode 属性

## 3、线程中断说明

​	Java 中的中断和操作系统的中断还不一样，这里就按照**状态**来理解。中断代表线程状态，每个线程都关联了一个中断状态，是一个 true 或 false 的 boolean 值，初始值为 false。

如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到：

​	1、来自 Object 类的 wait()、wait(long)、wait(long, int)，

​		  来自 Thread 类的 join()、join(long)、join(long, int)、sleep(long)、sleep(long, int)

> 这几个方法的相同之处是，方法上都有: throws InterruptedException 	

​	2、实现了 InterruptibleChannel 接口的类中的一些 I/O 阻塞操作，如 DatagramChannel 中的 connect 方法和 receive 方法等

​	3、Selector 中的 select 方法，NIO里面

# AQS介绍三

> https://javadoop.com/

AQS定义两种资源共享方式：

**Exclusive**（独占）：只有一个线程能执行，如 `ReentrantLock`。又可分为公平锁和非公平锁，`ReentrantLock` 同时支持两种锁。

- **公平锁** ：按照线程在队列中的排队顺序，先到者先拿到锁
- **非公平锁** ：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒

**Share**（共享）：多个线程可同时执行，如 `Semaphore/CountDownLatch`。`Semaphore`、`CountDownLatch`、 `CyclicBarrier`、`ReadWriteLock`。

**AQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的钩子方法：**

```java
//独占方式。尝试获取资源，成功则返回true，失败则返回false。
protected boolean tryAcquire(int)
    
//独占方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryRelease(int)
    
//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。    
protected boolean tryAcquireShared(int)
    
//共享方式。尝试释放资源，成功则返回true，失败则返回false。    
protected boolean tryReleaseShared(int)
    
//该线程是否正在独占资源。只有用到condition才需要去实现它。    
protected boolean isHeldExclusively()
```

## 1、CountDownLatch（倒计时器）

CountDownLatch，我们只需要关心两个方法。CountDownLatch 基于 AQS 的共享模式的使用。

​	countDown() 方法：每次调用都会将 state 减 1，直到 state 的值为 0。

​	await（）方法： 是一个阻塞方法，当 state 减为 0 的时候，await 方法才会返回。await 可以被多个线程调用，所有调用了 await 方法的线程阻塞在 AQS 的阻塞队列中，等待条件满足（state == 0），将线程从队列中一个个唤醒过来。`await()` 方法之后的语句得到执行。

### countdown（）方法

​	1、releaseShared（），

​	2、tryReleaseShared（），自旋的方法实现 state 减 1

​	3、doReleaseShared（），唤醒 await 的线程

​	4、unparkSuccessor（），唤醒 head 的后继节点，就是阻塞队列中的第一个节点

### await（）方法

​	1、acquireSharedInterruptibly（）

​	2、tryAcquireShared（），

​	3、doAcquireSharedInterruptibly（），先不考虑中断情况

​	4、执行setHeadAndPropagate（）

​	5、又执行doReleaseShared（） 此时唤醒head不是空节点，是阻塞队列后续节点。

### 两种典型用法

​	**1、某一线程在开始运行前等待 n 个线程执行完毕。**

​	一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

​	**2、实现多个线程开始执行任务的最大并行性。**

​	强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。

## 2、CyclicBarrier（循环栅栏）

CyclicBarrier 基于 Condition 来实现。

### nextGeneration（）方法

​	开启新的一代，类似于重新实例化一个 CyclicBarrier 实例

```java
// 开启新的一代，当最后一个线程到达栅栏上的时候，调用这个方法来唤醒其他线程，同时初始化“下一代”
private void nextGeneration() {
    // 首先，需要唤醒所有的在栅栏上等待的线程
    trip.signalAll();
    // 更新 count 的值
    count = parties;
    // 重新生成“新一代”
    generation = new Generation();
}
```

### breakBarrier（）方法

​	打破栅栏

```java
private void breakBarrier() {
    // 设置状态 broken 为 true
    generation.broken = true;
    // 重置 count 为初始值 parties
    count = parties;
    // 唤醒所有已经在等待的线程
    trip.signalAll();
}
```

### await（）方法

​	1、dowait（）

​	2、 condition 的 await() 会释放锁，被 signal() 唤醒的时候需要重新获取锁。先获取锁，

lock.lock()

​	3、检查栅栏是否被打破，是抛出异常，检查中断状态，中断了，抛出异常

​	4、所有线程都到栅栏后，执行nextGeneration（），唤醒等待线程，开启下一代

​	5、抛异常，执行打破栅栏breakBarrier();

什么时候栅栏会打破：

​	1、中断，我们说了，如果某个等待的线程发生了中断，那么会打破栅栏，同时抛出 InterruptedException 异常；

​	2、超时，打破栅栏，同时抛出 TimeoutException 异常；

​	3、指定执行的操作抛出了异常



### CyclicBarrier 和 CountDownLatch 的区别

CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行，CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行

CountDownLatch是一次性的，CyclicBarrier 可以重复使用。

## 3、Semaphore（信号量）

它类似一个资源池（可以类比线程池），每个线程需要调用 acquire() 方法获取资源，然后才能执行，执行完后，需要 release 资源，让给其他的线程用。

semaphore 其实也是 AQS 中共享锁的使用，因为每个线程共享一个池。

`Semaphore` 有两种模式，公平模式和非公平模式。

解读：创建 Semaphore 实例的时候，需要一个参数 permits，这个基本上可以确定是设置给 AQS 的 state 的，然后每个线程调用 acquire 的时候，执行 state = state - 1，release 的时候执行 state = state + 1，当然，acquire  的时候，如果 state = 0，说明没有资源了，需要等待其他线程 release。

# 二

## 3、对锁的认识

> https://tech.meituan.com/2018/11/15/java-lock.html   美团[不可不说的Java“锁”事](https://tech.meituan.com/2018/11/15/java-lock.html)

```shell
#锁分类
线程是否需要锁住同步资源:
	锁住：悲观锁
	不锁住：乐观锁
锁住同步资源，线程要不要阻塞:
	不阻塞：自旋锁、适应性自旋锁
多个线程竞争同步资源流程细节：
	不锁住资源，多个线程只有一个能成功，其他重试：无锁
	同一个线程执行同步资源自动获取资源：偏向锁
	多个线程竞争同步资源，没有获取到资源的线程自旋等待锁释放：轻量级锁
	多个线程竞争同步资源，没有获取到资源的线程阻塞等待唤醒：重量级锁
多个线程竞争要不要排队：
	排队：公平锁
	先尝试插队，插队失败后排队：非公平锁
一个线程中多个流程能不能获取同一把锁：
	能：可重入锁
	不能：非可重入锁
多个线程能不能共享一把锁：
	能：共享锁
	不能：独占锁
	
#1、悲观锁和乐观锁
悲观锁：
	对于同一数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候就先加锁，确保不会被其他线程修改。
	synchronized和lock锁实现都是悲观锁。
	适合写操作多的场景。
乐观锁：
	认为自己在使用数据的时，不会有被其它线程修改数据，不添加锁。更新数据的时候，去判断之前有没有线程更新这个数据，没有更新，就将自己的数据成功写入。有更新，根据情况执行不同操作（报错或者重试等）。
	最常用就是通过CAS算法实现，原子类就是通过CAS自旋实现的。
	适合读操作多的场景。

#2、自旋锁和适应性自旋锁
自旋锁：
	阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。让当前线程进行自旋，避免线程切换的开销，就是自旋锁。
	自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。
自适应自旋锁：
	自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

#无锁、偏向锁、轻量级锁、重量级锁
	这四种锁是指锁的状态，专门针对synchronized的。
	引入概念，Java对象头（主要包括标记字段、类型指针）和Monitor（同步对象，每一个Java对象都有一把看不见的锁，称为内部锁。线程私有，synchronized通过Monitor来实现线程同步）
	目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。
	总结：
		无锁是修改操作在循环内进行，线程会不断的尝试修改共享资源。
		偏向锁是通过标记字段解决加锁问题，避免CAS操作。
		轻量级锁通过CAS操作和自旋解决加锁问题，避免线程阻塞和唤醒而影响性能。
		重量级锁是将拥有锁的线程以为的线程都阻塞。

#公平锁和非公平锁
公平锁
	优点：等待线程不会被饿死。
	缺点：整体吞吐效率相对非公平锁要低。
非公平锁：
	优点：减少唤醒线程的开销，整体的吞吐效率高。
	缺点：可能存在线程被饿死。
	
#可重入锁和非可重入锁
	Java的ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是避免死锁。
	
#独占锁和共享锁
独占锁：
	锁一次只能被一个线程所持有，synchronized和lock都是独占锁。
共享锁：
	锁可被多个线程所持有。
	独占锁和共享锁通过AQS实现，通过不同的方法，来实现独占和共享。
```

## 4、对mysql的事务隔离级别的认识

```shell
事务特性ACID
	原子性、一致性、隔离性、持久性

SQL标准定义了四个隔离级别
	READ-UNCOMMITTED（读取未提交）：最低的隔离级别，允许读取尚未提交的数据变更。可能会导致脏读、幻读、不可重复读。
	READ-COMMITTED（读取已提交）：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发送。
	REPEATABLE-READ（可重复读）：对同一个字段多次读取的结果都是一直的，除非数据是被本身事务自己所修改。可以阻止脏读和不可重复读，幻读仍有可能产生。
	SERIALIZABLE（可串行化）：最高的隔离级别，完全服从ACID的隔离级别，所有的事务逐个执行，事务之间不可以产生干扰。可以阻止脏读、不可重复读、幻读。

	MySQL InnoDB存储引擎默认支持的隔离级别是REPEATABLE-READ（可重复读）。

	InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。
```

## 5、对数据库引擎的认识

```shell
MyISAM 和 InnoDB的区别
5.5之前MyISAM是默认的存储引擎，5.5之后，InnoDB是默认的存储引擎

#是否支持行级锁
	MyISAM只有表级锁，InnoDB支持行级锁和表级锁。默认为行级锁
#是否支持事务
	MyISAM不支持，InnoDB支持，具体提交和回滚事务的能力
#是否支持外键
	MyISAM不支持，InnoDB支持
#是否支持异常崩溃后的安全恢复
	MyISAM不支持，InnoDB支持，恢复过程依赖redo log日志。
	ps:
	InnoDB使用redo log(重做日志)保证事务的持久性，undo log(回滚日志)保证事务的原子性。通过锁机制、MVVC等方法保证事务的隔离性。（默认隔离级别REPEATABLE-READ(可重复读)）
#是否支持MVVC
	MyISAM不支持，InnoDB支持。
	MVVC是行级锁的一个升级，可以有效减少加锁操作，提高性能。

#InnoDB锁的算法有三种
	Record lock：记录锁，单个行记录上的锁。
	Gap lock：间隙锁，锁定一个范围，不包括记录本身。
	Next-key lock：Record + gap 临建锁，锁定一个范围，包括记录本身。	
```

# MVCC

> https://www.cnblogs.com/xuwc/p/13873611.html

## 什么是MVCC

​	`MVCC`，全称`Multi-Version Concurrency Control`，即多版本并发控制。

​	多版本控制: 指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，**只有写写之间相互阻塞，其他三种操作都可以并行**。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

## 什么是当前读和快照读

**当前读**

​	像select lock in share mode（共享锁），select for update；update，insert，delete（排他锁），这些操作都是一种当前读。**当前读就是当前读取的是记录的最新版本，读取时还要保证其他事务不能修改当前记录，会对读取的记录进行加锁。**

**快照读**

​	像`不加锁`的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC，MVCC是行锁的一个变种，在很多情况下，避免了加锁操作，降低了开销；因为是基于多版本，即快照读可能读到的并不一定是数据的最新版本，有可能是之前的历史版本。

​	**MVCC就是为了实现读-写冲突不加锁，而这个读指的就是`快照读`, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现**



## MVCC带来的好处

​	用来解决`读-写冲突`的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。解决了下面的问题

​	1）可以做到读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能。

​	2）还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题。

## MVCC的实现原理

​	MVCC模型在MySQL中的具体实现则是由 `3个隐式字段`，`undo日志` ，`Read View` 等去完成的

## 小结

​	MVCC是解决数据库只采用锁这种性能不佳的形式去解决读-写冲突问题。有了MVCC，可以有下面的组合方案。

​	MVCC +悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突。

​	MVCC +乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突。

# 二

## 6、数据库索引的bTree和hash的原理的区别

```shell
	索引是一种快速查询、检索数据的数据结构。常见的索引结构有：B树、B+树和hash

#hash结构
	hash是任意长度的输入经过hash算法转化为固定长度输出。
	hash算法效率高，不可逆，冲突少
	如果出现冲突，可以采用的解决方法：链地址法、开放地址法、再hash法
	
	采用hash算法，通过key找到index，找到index也就找到了对应的value。
#hash作为索引的话会有什么问题
	1、hash冲突问题
	2、hash索引不支持顺序和范围查询（Hash 索引不支持顺序和范围查询是它最大的缺点： 假如我们要对表中的数据进行排序或者进行范围查询，Hash索引就不行了）

#B树和B+树
	B树也称B-树,全称为多路平衡查找树，B 树和 B+树中的B是Balanced（平衡）的意思。
	目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。
	
#B树& B+树两者区别
	1、B树所有节点既存放键key，也存放数据data，而B+树只有叶子节点存放key和data。
	2、B树的叶子节点都是独立的，B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
	3、B树的检索过程是对范围内的节点关键字二分查找，可能还没到达叶子节点，检索就结束了。B+树，任务查找都是根节点到叶子节点的过程，检索效率稳定。

#NyISAM和InnoDB,B+树的实现区别
	MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是，两者的实现方式不太一样。
	MyISAM，索引文件和数据文件是分离的，B+树叶子节点的data存放的数据记录的地址，检索时，指定的key存在，以data的地址读取相应的数据记录。称为"非聚簇索引"。
	InnoDB中，数据文件本身就是索引文件。树的叶节点data保存了完整的数据记录，索引key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为"聚簇索引"。其余的索引都是辅助索引，辅助索引的data存储相应记录主键的值。检索是，主索引搜索，找到key就取出数据。辅助索引搜索，找到key，取出data的主键值，然后再走一遍主索引，"回表"。
	
树介绍：https://blog.csdn.net/nandao158/article/details/114065093
聚簇索引和非聚簇索引：https://www.cnblogs.com/aspnethot/articles/1504082.html
```

# 索引类型

## 主键索引和辅助索引（二级索引）

### 1、主键索引

​	数据表的主键列使用的就是主键索引，一张数据表有只能有一个主键，并且主键不能为 null，不能重复。

​	InnoDB的表中，当没有显示指定表的主键时，InnoDB会自动先检查表中是否有唯一索引且不允许null值的字段，如果有，就选择该字段为默认的主键。否则InnoDB将会自动创建一个6Byte的自增主键。

### 2、辅助索引（二级索引）

​		因为辅助索引的叶子节点存储的数据是主键，也就是通过二级索引，可以定位主键的位置。

​	唯一索引、普通索引、前缀索引、全文索引等索引都属于二级索引。

## 聚集索引与非聚集索引

### 1、聚集索引

**聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**

优点：

​	聚集索引的查询速度非常的快。

缺点：

​	1）**依赖有序的数据**，（数据不是有序的，就需要在插入时排序，字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。）。

​	2）**更新代价大**，索引列的数据被修改时，对应的索引也将被修改，叶子节点还存放着数据，修改代价大。所以对于主键索引来说，主键一般都是不可被修改的。

### 2、非聚集索引

**非聚集索引即索引结构和数据分开存放的索引。二级索引属于非聚集索引。**

优点：

​	更新代价比聚集索引小。

缺点：

​	1）也依赖有序的数据。

​	2）可能会二次查询（回表）。

不回表的情况，举例：用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。

```sql
SELECT name FROM table WHERE name='guang19';
```

索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。引出覆盖索引。

## 覆盖索引

**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。**

> 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。
>
> 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。

# 二

## 7、Redis的日常使用环境有哪些，都是怎么用的

```shell
#五大数据类型
string(字符串)、hash（哈希）、list(列表)、set(集合)、zset(有序集合)

计数：点赞数、点击数（string）
缓存：验证码、字典、（string）

记录热榜贴子ID列表（zset）

相关信息推荐（list）

消息队列（list）


```

## 8、redis的认识

```shell
见下面
```

# Redis

## 一、数据结构与对象

### 简单动态字符串

SDS：

**int free**（记录buf数组中未使用字节的数量）。

**int len**（记录buf中已使用字节的数量，等于SDS保存字符串的长度）。 

**char buf[]**（字节数组，用于保存字符串）。

通过未使用空间，SDS实现了空间预分配和惰性空间释放。

​	**1）空间预分配**，当对SDS修改时，对SDS空间扩展，程序不仅会为SDS分配必须要的空间

，还会分配额外的未使用空间。

​	例如：小于1MB   len + free + 1 = buf[]，大于等于1MB,len + 1 MB + 1byte = buf[]

​	通过空间预分配，Redis减少连续执行字符串增长所需的内存分配次数。

​	例如：len5 +free 5 ，扩展需要3个，就直接取free的空余的。变成是len8 +free 2.

​	SDS扩展时，先检查未使用空间释放足够，足够就无须执行内存重分配。

​	**2）惰性空间释放**，字符串缩短时，不会立即内存分配回收缩短的字节。

​	例如：len5 + free5 ，缩短未2时，变成len2 + free8。未使用空间保留在free中，避免SDS增长时，减少内存分配次数。

​	同时SDS提供了释放SDS未使用空间API，不用担心惰性空间释放造成内存浪费。

​	**总结**

 Redis只会使用C字符串作为字面量，在大多数情况下，Redis使用SDS作为字符串表示

 SDS的优点：

 **1、获取字符串长度，时间复杂度。O(1)**

 **2、杜绝缓存区溢出。**

 **3、减少修改字符串长度所需的内存重分配次数。**

 **4、二进制安全。**

 **5、兼容部分C字符串函数。**



### 链表

listNode节点包含：listNode prev（前节点）、listNode next （后节点）、value （节点的值）

list结构：实现**list键**底层之一

**listNode head**（表头节点）

**listNode tail**（表尾节点）

**long len** （链表包含的节点数量）

**dup**（节点值负责函数）

**free** （节点值释放函数）

**match** （节点值对比函数）

Redis链表特点：

> **双端**：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点复杂度都是O(1)
>
> **无环**：表头节点的prev指针和表尾节点的next指针都指向null，对于链表访问null为终点
>
> **带表头指针和表尾指针**：list结构的head指针和tail指针，获取表头表尾复杂度为O（1）
>
> **带链表长度计数器**：list结果的len属性对list持有的链表行计数，节点数量复杂度为O（1）
>
> **多态**：链表节点使用void* 指针保存节点值，可以通过dup、free、match三个属性为节点设置类型特定函数，所以链表可以用于保存不同类型的值。

**总结：**

**1、链表被广泛用于实现redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等。**

**2、每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis链表实现是双端链表。**

**3、每个链表使用一个list结构来表示，带有表头指针、表尾指针、链表长度等信息。**

**4、链表前置节点和后置节点都指向NULL，链表是无环链表。**

**5、链表设置不同类型特定函数，可以保存不同类型的值。**



### 字典

字典，一种用于保存键值对的抽象数据结构。字典中的每个建都是独一无二的。

字典在Redis的应用广泛，比如Redis的数据库、对**数据库**的增删改查都是构建在字典操作上的。字典也是**哈希键（Hash）**的底层实现之一，当一个哈希键包含的键值对比较多，或者键值对都是比较长的字符串是。Redis就会使用字典作为哈希键的底层实现。

Redis的字典底层使用**哈希表**实现，一个哈希表可以有多个**哈希节点**，每个哈希节点就保存字典的一个键值对。

**哈希表 dictht**

**dictEntry table**：哈希表数组

**long size**：哈希表大小

**long sizemask**：哈希表大小掩码，用于计算索引值，总是等于size-1

**long used**：哈希表已有节点的数量

table属性是一个数组，数组中的每个元素都是一个指向dictEntry结构的指针，每个dictEntry结构保存一个键值对，size属性记录哈希表的大小，就是table数组的大小，used熟悉记录hash目前已有节点（键值对）的数量。sizemask属性，size-1，这个属性和哈希值一起就觉得一个键该被放到table数组的那个索引上面。

**哈希表节点dictEntry**

**key** ：键

**v** ：值

**dictEntry next**：指向下一个哈希表节点，形成链表

key属性保存这键值对中的键，v保存键值对中的值。next是另外一个哈希表节点的指针，这个指针将多个哈希值相同的键值对连接在一起，解决hash值冲突的问题。**即Redis的哈希表使用链地址法解决键冲突**

**字典dict**

**dictType type**：特定函数

**privdata**：私有数据

**dictht ht[2]**：哈希表

**trehashidx ：**rehash索引，当rehash不在进行时，值为-1

type属性和privdata属性是针对不同类型的键值对，为创建多态字典设置的，type是一个指向dictType的指针，没个dictType保存一簇用于操作特定类型键值对的函数。privdata属性保存那些需要传给特定函数的可选参数。ht属性是包含两个项的数组，一般情况都是ht[0]哈希表，ht[1]是对ht[0]进行rehash使用的。rehashidx，记录了rehash目前的进度，rehash是记录，没有rehash，值为-1.

dictType中有：计算哈希值的函数、复制键的函数、复制值的函数、对比键的函数、销毁键的函数、销毁值的函数

**字典-->哈希表-->哈希节点**

**总结：**

**1、字典被广泛用于实现Redis的各种功能，包括数据库和哈希键。**

**2、Redis中的字典使用哈希表作为底层实现，每个字典带有两个哈希表，一个平时使用，一个仅在rehash时使用。**

**3、字典用作数据库实现或者哈希键实现是，使用MurmurHash2算法法计算哈希值。**

**4、哈希表使用链地址法解决冲突。**

**5、哈希表的扩展和收缩，通过rehash到新哈希表中，过程不是一次性完成的，是将进式的完成。**



### 跳跃表

跳跃表是有序数据结构，通过每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。

跳跃表平均O（logN）、最坏O（N）查找。Redis中，有序集合中包含元素多，或者有序集合中元素是比较长的字符串是，**使用跳跃表作为有序集合键（zset）的底层实现。**

**zskiplistNode（跳跃表节点）**：

**level[]** : 层，每个层就带有两个属性，前进指针和跨度

**backward**：后退指针，指向当前节点的前一个节点。从表尾向表头遍历时使用

**score**：分值，节点按照锁保存的分值从小到大排列。

**obj**：成员对象，节点保存的成员对象

>  具体介绍看5.1.1页，Redis的设计与实现

**zskiplist（跳跃表）**

**skiplistNode** **header：**表头节点

**skiplistNode** **tail**：表尾节点

**length**：节点的数量

**level**：表中层数最多的节点的层数

header和tail指针，指向跳跃表的表头和表尾节点，通过这个两个指针，程序定位表头节点和表尾节点的复杂度O（1），通过length获取记录节点的数量，复杂度O（1），level属性获取跳跃表层高最大的节点层数量。复杂度O（1）。

**总结**

**1、跳跃表是有序集合键的底层实现之一。**

**2、Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，zskiplist保存跳跃表的信息，zskiplistNode用于展示跳跃表节点。**

**3、每个跳跃表节点的高度都是1-32之间的随机数。**

**4、同一个跳跃表中，多个节点可以包含相同的分值，每个节点的成员对象必须是唯一的。**

**5、跳跃表的节点按照分值大小进行排序，分值相同是，节点按照成员对象的大小进行排序。**



### 整数集合

**整数集合是集合键（set）的底层实现之一**，当一个集合值包含整数值元素，并且元素不多时，就会使用整数集合作为集合键的底层实现。

**intset整数集合**

**encoding**：编码方式

**length**：集合包含的元素数量

**contents**[]：保存元素的数组

contents数组是整数集合的底层实现，各个项按照值的大小从小到大有序排列，并且数组中不能有任何重复项，

**总结**：

**1、整数集合是集合键的底层实现之一。**

**2、整数集合的底层实现为数组，这个数组以有序、无重复的方式保存集合元素，在有需要时，程序会根据新添加的元素的类型，改变这个数组的类型。**

**3、升级操作为整数集合带来了操作上的灵活性，并尽可能的节约了内存。**

**4、整数集合只支持升级操作，不支持降级操作。**



### 压缩列表

**压缩列表（ziplist）是列表键（list）和哈希键（hash）的底层实现之一。**列表键包含少量项，或者每个项要么是小整数值，要么是短的字符串。Redis就用压缩列表来做列表键的底层实现。哈希键同理。

**总结**：

**1、压缩列表是一种为节约内存而开发的顺序型数据结构。**

**2、压缩列表被用作列表键和哈希键的底层实现之一。**

**3、压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。**

**4、添加新节点到压缩列表，或者从压缩列表中删除节点，可能会引发连锁更新操作，但这个操作出现的几率不高。**



### 对象

Redis并没有直接使用**简单字符串、双端链表、字典、压缩列表、和整数集合**等。而且基于这些数据结构创造了一个对象系统，这个系统包含**字符串对象、列表对象、哈希对象、集合对象、有序集合对象**这五种类型对象。每种对象都用到了至少一种前面所介绍的数据结构。

​	当我们在Redis数据库新创建一个键值对是，至少会创建两个对象，一个键对象，一个值对象

**redisObject （redis对象）**

**type**：类型，记录对象的类型

**encoding**：编码

**ptr**：指向底层实现数据结构的指针

...

​	**Redis数据库保存的键值对，键总是一个字符串对象类型，值可以是字符串对象、列表对象、哈希对象、集合对象、有序集合对象其中一种类型。**

​	type  + 键，显示值对象类型，例：

```shell
redis> set msg "hello"
ok
redis> type msg
string
...rpush numbers 1 3 5  	type numbers 	list
...hmset profile name tom 	type profile 	hash
...sadd	fruits apple banana	type fruits		set
...zsadd price 8.5 apple 	type price		zset	
```

**encoding**属性决定**ptr**指针指向对象的底层实现数据结构，每种类型的对象都至少使用了两种不同的编码。

使用object encoding  + 键，可以查看一个数据库键的值对象的编码

> 详看8.1.2 Redis的设计与实现（第二版）

#### 字符串对象

字符串对象编码可以是int（整数值）、raw（简单动态字符串）、embstr（embstr编码的简单动态字符串）

转换int-->raw,embstr->raw

#### 列表对象

列表对象的编码可以是ziplist（压缩列表）、linkedlist（双端链表）

注意：linkedlist编码的列表对象在底层的双端链表结构中包含了多个字符串对象，这种嵌套字符串对象的行为在稍后介绍的哈希对象、集合对象、有序集合对象中都会出现，**字符串对象是Redis五种类型对象中唯一一个会被其他四种类型对象嵌套的对象。**

转换为ziplist-->linkedlist

#### 哈希对象

哈希对象的编码可以是ziplist（压缩列表）、hashtable（HT字典）

转换为ziplist-->hashtable

#### 集合对象

集合对象的编码可以是intset（整数集合）、hashtable（HT字典）

转换为intset-->hashtable

#### 有序集合对象

有序集合对象的编码可以是ziplist（压缩列表）、skiplist（跳跃表）

装换为ziplist-->skiplist

#### 类型检查于命令多态

Redis用于操作的命令可以分为两种类型。

1、一种命令可以对任何类型键执行，比如

​		del（删除）、expire（到期）、rename（重命名）、type（类型）、object（对象编码）等。

2、一种命令只能对特定类型的键执行，比如

​		set、get、append、strlen等对字符串键；

​		hdel、hset、hget、hlen等对哈希键；

​		rpush、lpop、linsert、llen等对列表键；

​		sadd、spop、sinter、scard等对集合键；

​		zadd、zcard、zrank、zscore等对有序集合键；

**类型检查**：redis通过检测redisobject键对象的type属性，发现是特定的命令，如果不匹配。就返回类型错误。

命令多态：因为实现对象的编码可以不同，比如列表对象有ziplist和linkedlist，ziplist编码通过ziplistLen函数返回长度，linkedlist通过listLength返回长度。我们使用llen是，llen命令就是多态的。

#### 内存回收

**redisObject属性：refcount**  引用次数，记录每个对象的引用次数，创建对象初始化为1，变成0后，对象所占的内存会被释放。

Redis是通过**引用计数法**实现内存回收的。

#### 对象共享

redisObject属性：refcount  引用次数

目前Redis在初始化服务器是，会创建一万个字符串对，这些对象从0到9999的整数值，服务器需要用到这些值是，就使用这些共享对象，不创建新对象。这个数量可以通过参数修改。

#### 对象的空转时长

**redisObjcet属性：lru ，**记录对象最后一次被命令程序访问的时间。

object idletime + 键。打印指定键的空转时长，通过当前时间减去键对象的lru时间得出来的。

**object idletime命令是特殊的，访问键时，不会修改对象lru属性。**

除了可以查看信息外，空转时长另一个作用是。服务器打开了maxmemory（最大内存）选择时，服务器占用的内存数超过maxmemory设置的上限值，空转时长较高的键会优先被服务器释放，从而回收内存。

**总结：**

**1、Redis数据库中的每个键值对的键和值都是一个对象。**

**2、Redis有字符串、列表、哈希、集合、有序集合五种类型的对象。每种对象至少有两种或以上的编码方式，不同的编码在不同的使用场景优化对象使用效率。**

**3、服务器执行命令前，会先检测给定键能否执行指定的命令。检查一个键的类型，就是检查键的值对象类型。**

**4、Redis使用引用计数法实现内存回收机制。**

**5、Redis的共享值为0到9999的字符串对象。**

**6、对象会记录自己最后一次被访问的时间，这个时间用户计算对象的空转时间。**

## 二、单机数据库的实现

### 数据库

服务器中的数据库，默认为16个，0-15 未指定，默认为0

#### 切换数据库

默认目标数据库是0号数据库，客户端可以通过select切换

#### 数据库键空间

**redisDb结构：dict dict字典**，  数据库键空间字典，保存着数据库中所以键值对。

#### 设置键的生成时间或过期时间

**redisDb结构：dict expires** ，数据库过期字典，保存着键的过期时间。

#### 过期键的删除策略

定时删除：设置键的过期时间，同时创建一个定时器，让定时器在键的过期时间来临时，执行键的删除操作。

​	缺点：定时删除占用太多CPU时间，影响服务器的响应时间和吞吐量。

惰性删除：放任键不管，每次从键空间获取键是，检测是否过期，过期就删除，没过期。返回该键。

​	缺点：浪费太多内存，有内存泄露风险。

定期删除：每隔一段时间，就检查一次，删除过期键。

​	服务器需要根据情况，合理的设置删除操作的执行时长和执行频率。

**Redis服务器是有的是惰性删除和定期删除两种策略。**

#### AOF、RDB和复制功能对过期键的处理

**RDB文件**

​	执行save命令，生成RDB文件，程序对数据库中的键检查，过期的键不会保存到创建的RDB文件中。

​	启动Redis，如果服务开启了RDB功能，对RDB文件进行载入。

​	注意：如果服务器以主服务器模式运行，载入RDB文件时，程序会对文件保存的键检查。过期键被忽略。

​				如果服务器是从服务器模式运行，载入RDB文件时，所有键都会载入到数据库中。主从同步时，从服务器数据库会被清空，所有也不会造成影响。

**AOF文件**

​	服务器以AOF持久化模式运行，如果某个键已经过期，还没被惰性删除或者定期删除，AOF文件不会因为这个过期键而产生影响。当惰性删除或者定期删除之后，程序会给AOF文件追加一条DEL命令，显式记录该键被删除。

​	AOF重写，程序会检查键，过期的键不会保存到重写后的AOF文件。

​	服务器运行咋复制模式下，服务器的过期键删除都是由主服务器控制。

#### 数据库通知

这个功能可以让客户端通过订阅给定的频道或者模式，来获取数据库中键的变化，以及数据库中命令的执行情况。

**总结：**

**1、Redis服务器的所有数据库都保存在redisServer.db数组中，而数据库的数量有redisServer.dbnums属性保存。**

**2、客户端通过修改目标数据库指针，让它指向redisServer.db数组中的不同元素来切换不同的数据库。**

**3、数据库主要有dict和expires两个字典构成，dict字典保存键值对，expires字典保存键过期时间。**

**4、数据库是由字典构成，数据库操作都是建立在字典操作之上的。**

**5、数据库键总是一个字符串对象，值可以是任意一直Redis对象。包括字符串对象、哈希表对象、列表对象、集合对象、和有序集合对象。**

**6、expires字典的键指向数据库的某个键，值记录键过期时间，过期时间是一个毫秒单位的UNIX时间戳。**

**7、Redis使用惰性删除和定期删除来删除过期的键。惰性删除时使用是判断删除，定期是根据设置的时间，主动查找并删除。**

**8、执行save命令或者bgSave命令产生的RDB文件不包含过期键。**

**9、执行bgReWriteAOF命令产生的重写AOF文件不包含过期的键。**

**10、当一个过期键被删除之后，服务器会追加一条del到现有的AOF文件末尾。显式的删除过期键**

**11、当主服务删除过期键后，会向所以从服务器发送一条del命令。显式的删除过期键。**

**12、从服务器发现过期键不会删除他，而是等待主节点发来del命令。这种统一、中心话的方式保证主从服务器的一致性。**

### RDB持久化

​	RDB持久化可以手动执行，也可以根据服务器配置定期执行，可以将某一个时间点上的数据库状态保存到一个RDB文件中。

#### 	RDB文件创建

​		两个命令：

​			save：阻塞服务器进程，直到RDB文件创建完毕。

​			bgsave：派生子进程，由子进程创建RDB文件，不阻塞服务器。

#### 	RDB文件载入

​		服务器启动时自动执行的，没有单独的载入命令。只要Redis服务器启动时检测到RDB文件，就会自动载入。

​		注意：AOF文件的更新频率比RDB文件高，服务器开启了AOF持久化功能，会优先使用AOF文件来还原数据库状态。AOF关闭状态时，才会使用RDB文件。

​		载入时服务器一直处于阻塞状态，直到载入完成。

**总结**

**1、RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据。**

**2、save命令由服务器直接执行保存操作，会阻塞服务器。**

**3、bgsave由子进程执行保存操作，不会阻塞服务器。**

**4、服务器状态会保存所有用save选项设置的保存条件，当任意一个保存条件被满足时，服务器自动执行bgsave命令。**

**5、RDB文件是一个经过压缩的二进制文件，由多个部分组成。**

**6、对于不同类似的键值对，RDB文件会使用不同的方式来保存他们。**

### AOF持久化

#### AOF持久化

​	AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。

​	AOF持久化功能的实现可以分为命令追加、文件写入、文件同步三个步骤。

**命令追加**

​	**AOF持久化打开状态时，服务器执行一个写命令，会以协议格式将执行的写命令追加到服务器状态的aof_buf缓存区的末尾。**

**文件写入与同步**

Redis的服务器进程就是一个事件循环loop，这个循环中的文件事件负责接收客户端的请求，以及向客户端发送命令回复，时间事件则负责执行（比如serverCron函数）定时运行的函数。服务器每次结束一个事件循环之前，都会调用flushAppendOnlyFile函数。考虑是否将aof_buf缓存区内容写入和保存到AOF文件里面。

**flushAppendOnlyFile函数的行为，由服务器配置的appendSync选项值决定。**

**always**：将aof_buf缓存区中的所有内容写入并同步到AOF文件。

**everysec**：将aof_buf缓存区的所有内容写入到AOF文件，如果上次同步AOF文件时间距离现在超过一秒钟，那么再次对AOF文件进行同步，这个同步由一个线程专门负责执行的。

**no**：将aof_buf缓存区所有内容写入到AOF文件，并不对AOF文件同步，何时同步由操作系统决定。

默认值：everysec

#### AOF文件载入与数据还原

​	服务器只要读入并重新执行一遍AOF文件里面的写命令，就可以还原服务器关闭之前的数据库状态。

#### AOF重写

​	通过AOF文件重写，AOF文件不会包含任何浪费空间的冗余命令。重写后的AOF文件保存的数据库状态相同，但是文件体积比旧AOF文件体积小很多。

​	AOF重写不对现有的AOF文件进行读取、分析或者写入操作。这个功能是直接读取服务器当前的数据库状态来实现的。读取现在键的值，然后用一条命令记录键值对，代替之前可能多条命令。

**总结**

**1、AOF文件通过保存所有修改数据库的写命令请求来记录服务器的数据库状态。**

**2、AOF文件中的所有命令都一Redis命令请求协议的格式保存。**

**3、命令请求会先保存到AOF缓冲去里面，之后再定期写入并同步到AOF文件。**

**4、appendsync选项不同值对AOF持久化功能的安全性已经Redis服务器的性能有很大影响。**

**5、服务器载入保存在AOF文件中的命令，就可以还原数据库本来的状态。**

**6、AOF重写产生一个新的AOF文件，这个文件比原有的AOF文件小，数据状态一样。**

**7、AOF重写不是读取，修改原有AOF文件，是通过读取数据库的键值对来实现的。**

**8、在执行重写bgReWriteAOF命令时，redis服务器会维护一个AOF重写缓存区，缓存区会在子进程创建AOF命令时，记录服务器执行的所有写命令。当子进程完成创建新的AOF文件后，服务器将重写缓冲区所有内容追加到新的AOF文件末尾，最后服务器用新的AOF文件替换旧的AOF文件，完成AOF文件重写。**

### 事件

Redis服务器是一个事件驱动程序，服务器需要以下两类事件

**文件事件**：Redis服务器通过套接字与客户端（或者其他Redis服务器）进行连接，文件事件就是服务器对套接字操作的抽象。服务器与客户端（或者其他Redis服务器）的通信会产生相应的文件事件，而服务器通过监听并处理这些事件来完成一系列的网络通信操作。

**时间事件**：Redis服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时器操作的抽象。

#### 文件事件

​	redis基于reactor模式开发的自己的网络事件处理器。

​	1、文件事件处理器使用I/O多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

​	2、当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作是，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字关联好的世界处理器来处理这些事件。

文件事件处理器由四个组成部分：套接字、I/O多了复用程序、文件事件分派器、事件处理器。

#### 时间事件

时间事件分为一下两类：

​	定时事件：让一段程序在指定的时间之后执行一次。

​	周期性事件：让一段程序每隔指定时间就执行一次。

一个时间事件由以下三个属性组成：

​	id：时间事件全局唯一ID，从小到大顺序递增，新事件的ID号比旧时间大。

​	when：毫秒精度UNIX时间戳，记录时间事件的到达时间。

​	timeProc：时间事件处理器，一个函数。时间事件到达时，服务器就会调用相应的处理器来处理事件。

​	目前Redis只有周期性事件，没有使用定时事件。

时间事件应用实例：**serverCron函数**

​	主要工作包括：

​	1、更新服务器的各类统计信息，比如时间，内存占用、数据库占用情况。

​	2、清理数据库中的过期键值对。

​	3、关闭和清理连接失效的客户端。

​	4、尝试进行AOF或RDB持久化操作。

​	5、服务器是主服务器，对从服务器进行定期同步。

​	6、集群模式，对集群进行定期同步和连接测试。

**总结**

**1、Redis服务器是一个事件驱动程序，服务器处理的事件分为时间事件和文件事件两类。**

**2、文件事件处理器是基于Reactor模式实现的网络通信程序。**

**3、文件事件是对套接字操作的抽象，每次套接字变为可应答、可写或可读时，相应的文件事件就会产生。**

**4、文件事件分为读事件和写事件两类。**

**5、时间事件分为定时事件和周期性事件，Redis目前只有周期性事件**

**6、服务器一般只执行serverCron函数一个时间事件，这个事件是周期性事件。**

**7、文件事件和时间事件之间是合作关系，服务轮流处理，不会进行抢占。**

**8、时间事件在文件事件后，事件之间不会出现抢占，所有通常会比设定的到达时间晚一点。**

# 二

## 9、redis除了做缓存外，还用来做什么

```shell
键过期功能、可以用来实现缓存。
发布订阅功能，可以用来实现消息系统。
简单的事务功能，能在一定程度上保证事务特性。
支持Lua脚本功能，可以利用lua创造新的Redis命令。
提供流水线功能，能将一批命令一次性传到Redis，减少网络开销。

排行榜系统（list、zset）
计数器应用（string）
社交网络（赞/踩、粉丝、共同好友/爱好等）
消息队列系统

string：缓存、计数、共享session、限速
hash：用户信息
list：消息队列、文章列表、
set：标签、
zset：排行榜系统


#分布式锁
	Reids2.8版本后加入了set指令的扩展参数，是的setnx和expire可以一起执行。
	set lock:codehole true ex 5 nx ok...do something ...>del lock:codehole

#异步消息队列
	list的数据结构作为异步消息队列使用，使用rpush/lpush操作入队列，使用lpop和rpop来出队列。
	队列延迟问题：使用blpop/brpop，解决lpop/rpop.b表示阻塞读，队列没有数据的时候，立即进入休眠状态，有数据到来，立刻醒过来，消息的延迟几乎为0.
	空闲连接自动断开：redis客户端闲置连接过久，会主动断开连接。blpop/brpop会抛出异常。所以客户端需要捕获异常，还要重试。
	
#延时队列实现
	Redis的zset有序列表实现。

#位图数据结构实现签到、是否登录
	bitmap位图数据结构
	
#HyperLogLog结构统计UV
	HyperLogLog提供不精确的去重计数方案，统计浏览用户数量，一天内同一个用户多次访问只能算一次。尽管它大概有0.81%的错误率，但对于统计UV（一天内独立访客数量）这种不需要很精确的数据是可以忽略不计的
	
#布隆过滤器判断元素是否存在，类似set但是比set更省空间90%
	邮箱的垃圾邮件过滤应用场景这种，爬虫系统URL过滤去重。
    布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

#简单限流
	通过zset实现，zset记录用户行为历史，每一个行为作为zset中的key保存。同一个用户同一种行为用一个zset记录。
	每一个行为到来是，维护一次时间窗口。讲时间窗口外的记录全部清理掉，值保留窗口内的记录。判断zset集合中score值，value值没有意义，只要保证唯一即可。

#漏斗限流
	redis4.0提供了限流redis-cell，而且保证了原子限流指令。
	cl.throttle 命令说明
	cl.throttle laoqian:reply 15 30 60 1
		key:laoqian:reply
		capaticy:漏斗容量  15 
		operations：漏斗次数 30 
		sencods :时间内s 60  漏斗速率就是30/60
		need 1 quota:可选参数 默认也为 1 
#地理模块GeoHash
	实现附近的功能
		
```

## 10、MySQL你常见的优化方案

```shell
https://www.jb51.net/article/234842.htm#_lab2_2_9
一、字段优化
	覆盖索引尽量用
二、where优化
	1、尽量全值匹配，组合索引时全值匹配
	2、最佳左前缀法则，组合索引，最左匹配
	3、范围条件放最后
	4、不在索引列上面做任何操作，会失效
	5、不等于要慎用，索引会失效，用覆盖索引可以避免
	6、null/not null有影响，会造成索引失效，根据查询条件区分。
	7、like查询小心使用，左like会失效，覆盖索引可以生效。
	8、字符类型加引号，列如数字字符串，不加索引会失效
三、优化
	or改union效率高，是有or大多数情况不使用索引，使用union可以。解决还是用覆盖索引
	
#硬核	
https://blog.csdn.net/aaa31203/article/details/119823527	
1、连接-配置优化，MySQL的配置。
	服务器端增加可用连接数，或者及时释放不活动的连接。
	客户端，减少服务端获取的连接数，引入连接池，实现连接的重用。
2、缓存-架构优化，数据架构。
	使用缓存，较少直接对数据库的访问。
	单机服务器满足不了，就用数据库集群方案。
	分库分表。垂直分库，减少并发压力。水平分表，解决存储瓶颈。
3、SQL语句分析与优化，SQL与索引使用。
	1）、可以打开慢查询日志开关，分析慢查询。
	2）、eXplanin执行计划分析。
	system > const > eq_ref > ref > range > index > all
	
	system:const的一种特例，只有一行满足条件。
	const：主键索引或者唯一索引，只能查到一条数据。
	eq_ref：通常出现在多表的 join 查询，表示对于前表的每一个结果,都只能匹配到后表的一行结果。一般是唯一性索引的查询（UNIQUE 或 PRIMARY KEY）。eq_ref 是除 const 之外最好的访问类型。
	system，const，eq_ref，都是可遇而不可求的，基本上很难优化到这个状态。
	
	ref：查询用到的非唯一索引，或者关联操作只使用了索引的最左前缀。
	range：索引范围查询。一般 where 后面是 between and 或 <或 > 或 >= 或 <=或 in 这些，type 类型就为 range。
	index：查询全部索引的数据（比不走索引要快）
	all：全部扫描，没有用到索引或者没有索引。
	
	优化type的连接类型，保证查询到达range级别，最好到达ref级别。
	all（全表扫描）和index（查询全部索引）都是需要优化的。

	Extra列：
		内容有using index，表示用到了覆盖索引，不需要回表。
		内容有using where，表示存储引擎返回的记录并不是所有的都满足查询条件，需要在server 层进行过滤，使用了where过滤。
		内容有using filesort，表示不能使用索引来排序，用到了额外的排序。需要排查。（复合索引的前提）
		内容有using temporary，表示用到了临时表，需要优化，例如创建复合索引。
4、存储引擎和表结构优化。
5、硬件和操作系统。
6、业务层面的优化。
	限流、引入MQ削峰等，减少数据库压力。
	如果关系型数据库解决不了的问题，我们可能需要用到搜索引擎或者大数据的方案了，并不是所有的数据都要放到关系型数据库存储。

```

## 11、JVM你常用的优化方案

```shell
#jvm常用命令解析
https://blog.csdn.net/aaa31203/article/details/119737642
1、jps 查看java进程
2、jinfo 实时查看和调整JVM配置参数
3、jstat 查看虚拟机性能和类装载和垃圾收集信息
4、jstack 查看线程堆栈信息，比如排查死锁
5、jmap 生成堆存储快照，打印堆内存相关信息

#jvm性能优化指南
1、内存
	内存分配：堆内存分配，新生代和老年代比例
	内存溢出：内存泄露导致内存泄露和大并发情况下
	大并发[秒杀]流程：
		热点数据缓存、验证码、集群+负载均衡、限流[令牌桶、漏桶算法]、队列、异步消息中间件、分布式锁、数据库锁、5分钟内没有支付、取消订单、恢复库存。
2、gc
	选用合适的GC垃圾收集器。
	
3、硬件
	硬件升级
	
#性能优化流程：
1、发现问题：
	GC频繁、死锁、OOM（内存溢出）、线程池不够用、CPU负载过高
2、排查问题：
	打印出GC日志，查看minor gc/major gc,结合工具gc viewer/gceasy.io
	jstack查看线程堆栈信息
	dump出堆文件，使用MAT或者其他工具分析
	合理使用jdk自带的console，jvisualvm，阿里的arthas等实时查看JVM状态
	灵活应用jps、jinfo、jstat、jmap等jvm常用命令
3、解决方案
	适当增加堆内存大小/选项合适的垃圾收集器
	使用zk、redis实现分布式锁
	设置本地，nginx等缓存减少对后台服务器的访问
	后端代码优化及时释放资源/合理设置线程池的参数
	集群部署减少单节点的压力
	利用消息中间件实现异步消息
	...
	
==========================================
C:\Users\CC>jps
41312 DemoApplication
41840 Launcher
48552 Jps
2444
27980 RemoteMavenServer36

C:\Users\CC>jinfo -flag MaxHeapSize 41312
-XX:MaxHeapSize=4223664128

C:\Users\CC>jstat -class 41312
Loaded  Bytes  Unloaded  Bytes     Time
 10057 18115.4        0     0.0       2.08
 
C:\Users\CC>jstack 41312
........内容太多..........

C:\Users\CC>jmap -heap 41312
.................

Heap Configuration:
   MinHeapFreeRatio         = 0
   MaxHeapFreeRatio         = 100
   MaxHeapSize              = 4223664128 (4028.0MB)
   NewSize                  = 88080384 (84.0MB)
   MaxNewSize               = 1407713280 (1342.5MB)
   OldSize                  = 176160768 (168.0MB)
   NewRatio                 = 2
   SurvivorRatio            = 8
   MetaspaceSize            = 21807104 (20.796875MB)
   CompressedClassSpaceSize = 1073741824 (1024.0MB)
   MaxMetaspaceSize         = 17592186044415 MB
   G1HeapRegionSize         = 0 (0.0MB)

Heap Usage:
PS Young Generation
Eden Space:
   capacity = 195035136 (186.0MB)
   used     = 171847536 (163.88658142089844MB)
   free     = 23187600 (22.113418579101562MB)
   88.11106528005293% used
From Space:
   capacity = 10485760 (10.0MB)
   used     = 10470368 (9.985321044921875MB)
   free     = 15392 (0.014678955078125MB)
   99.85321044921875% used
To Space:
   capacity = 16252928 (15.5MB)
   used     = 0 (0.0MB)
   free     = 16252928 (15.5MB)
   0.0% used
PS Old Generation
   capacity = 176685056 (168.5MB)
   used     = 19656760 (18.74614715576172MB)
   free     = 157028296 (149.75385284423828MB)
   11.125309884725056% used

23927 interned Strings occupying 2473240 bytes.
```

## 12、MySQL语句执行效率平时怎么检测的

```shell
看上面的第三点
```

## 13、消息中间件都使用了那些

```shell
#为什么使用消息队列
1、通过异步处理提高系统性能
2、削峰、限流
3、降低系统的耦合性

#常用的MQ产品对比
RabbitMQ：单机吞吐量：万级，适用稳定性要求的企业级应用。
RocketMQ：单机吞吐量：十万级，阿里系，国内互联网使用居多。
kafka：单机吞吐量：百万级，日志和大数据方向使用较多。
AactiveMQ：单机吞吐量：万级，维护越来越少，不建议再使用。

```

## 14、synchronize锁的升级有认识嘛

```shell
#为什么前期是重量锁
监视器所（monitor）依赖底层操作系统失效，java线程映射到原生线程上。唤醒和挂起都需要操作系统的帮忙。操作系统实现线程切换的时候需要从用户态转换到内核态，这个转换需要比较长的时间，时间成本相对较高。

#怎么使用synchronized
1、修改实例方法：作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁。
2、修饰静态方法：给当前类加锁，作用于类的所有对象实例，进入同步代码前要获得class的锁。
3、修饰代码块：指定加锁对象，可以是对象实例或者类。


#构造方法可以使用synchronized关键字修饰么？
构造方法本身属于线程安全，不存在同步的构造方法。所以不能使用synchronized修饰。


#synchronized的底层原理
javap查看synchronized类的相关字节码
	synchronized同步代码块的实现是monitorenter和monitorexit指定。执行这个指定，就是获取对象监视器的持有权。执行monitorenter指令，锁计数器加1，monitorexit指令，锁计数器减1.锁计数器为0时，表示锁被释放。
	synchronized同步方法块没有monitorenter和monitorexit指令，是用的ACC_synchronized表示，标识这个一个同步方法。
	两者的本质都是对对象监视器 monitor 的获取。

#synchronized的底层优化。
	jdk1.6对锁引进了大量的优化。锁主要存在的状态依次是：
	无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。线程会随竞争而逐渐升级，锁可以升级不能降级。

#synchronized和ReentrantLock的区别
1、都是可重入锁
2、synchronized依赖JVM，ReentrantLock依赖于API
3、ReentrantLock比synchronized相比，可以实现等待中断，实现公平锁，选择性通知。

#synchronized注意事项
不要使用synchronizede（String a）。因为JVM中，字符串常量池有缓存功能。
和下面的这个问题类似：
#synchronized不能同步Integer等类型
“Integer 和 String 类型的对象不适合做锁”，其实基本上所有的基础类型的包装类都不适合做锁，因为它们内部用到了享元模式，这会导致看上去私有的锁，其实是共有的；享元模式里面对数据进行了缓存，会导致好几部分代码拥有同一把锁。

一部分解释是：
	Java的自动封箱和拆箱，当执行interger++ 是创建一个新的integer对象，并赋值integer，导致integer一直每次加锁都加载不同的对象上，出现问题。


```

## 15、http和https的区别，这个s是什么

```shell
HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。

HTTP+SSL/TLS = HTTPS
SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。

1、https协议需要到申请证书。
2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
3、http端口是80，http是端口是443
4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
```

## 16、平时的设计模式有用那些，主要应用在那些场景

```shell
工厂设计模式、单例设计模式、代理设计模式、观察者模式、适配器模式、装饰者模式、模板方法模式。

工厂模式：发送通知消息
观察者模式：则当一个对象变化时，发出通知，其它依赖该对象的对象都会收到通知，并且随着变化。获取更新消息通知。
单例模式：
代理模式：事务处理、日志管理、权限控制
```

# 三

1、自我介绍

## 2、谈一下你对并发控制的认识

```shell
并发编程目的是提高程序的执行效率，提高程序运行速度。但是会出现的问题有内存泄露、死锁、线程不安全等问题。
并发编程三个重要的特性：
原子性：synchronized可以保证代码片段的原子性。
可见性：volatile关键字可以保证共享变量的可见性。
有序性：volatile 关键字可以禁止指令进行重排序优化，保证有序性。

#引入的并发JUC包
1、常见的并发容器
2、阻塞队列
3、AQS和AQS常用类
4、线程池
5、原子类
```

## 3、常见的锁有那些，他们怎么实现的

```shell
见上面的对锁的认识，引入美团的不可不说的锁事
```

## 4、JUC里面的常用类你都使用了那些

```shell
1、并发容器常用类
2、阻塞队列常用类
3、AQS常用类
4、线程池常用类
5、原子类常用类
```

## 5、MySQL的bTree说一下

```shell
见上面的mysql
```

## 6、Executor的使用介绍

```shell
线程工具类的使用，常用的方法
```

## 7、并发常用类介绍

```shell
1、并发容器常用类
2、阻塞队列常用类
3、AQS常用类
4、线程池常用类
5、原子类常用类
```

## 8、CAP是什么

```shell
CAP也就是Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性）。
一致性（C）：所有的节点访问同一份最新的数据副本。
可用性（A）：非故障的节点在合理的时间内返回合理的响应。（不是错误或者超时）
分区容错性（P）：分布式系统出现网络分区的时候，仍然能够对外提供服务。

出现网络分区的时候，我们才会讨论C一致性和A可用性。所以分布式系统理论上只能选择CP架构或者AP架构。
zookeeper就是CP架构。一致
eureka就是AP架构。可用
nocos支持CP和AP。默认是AP（可用）

注册中心是负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动是与注册中心交互，注册中心不转发请求，压力较小。
常见的注册中心组件有：zookeeper、eureka、nacos
1、zookeeper保证的是cp(一致性)：任何时刻对zookeeper的读请求都能得到一致的结果。不保证每次的请求可用性。比如在leader选举过程中或者超过半数以上的机器不可用的服务就是不可用的。
2、eureka保证的是ap（可用性）：在eureka中不存在leader节点，每个节点都是一样的、平等的。eureka不会想zookeeper那样出现选举过程中或者半数以上的机器不可用，服务就不可用。eurek保证有一个节点可以就提供正常服务，只不过可能这个节点上的数据不是最新的。
3、nacos支持AP和CP切换。默认AP（可用性）


#BASE理论：
BASE是Basically Available（基本可用）、soft-state（软状态）和eventually consistent（最终一致性）三个短语的缩写。
BASE理论是对CAP一致性C和可用性A权衡的结果。核心思想：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。

1、基本可用：指分布式系统出现不可预知故障的时候，允许损失部分可用性。
	什么叫允许损失部分可用性？
	响应时间变长、系统功能上的损失（部分功能暂时不可用）。
2、软状态：允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
3、最终一致性：系统中的所有数据副本，在经过一段时间后，最后达到一致的状态。不强调实时一致。

#一致性有三种级别
1、强一致性：实时一致
2、弱一致性：不保证什么时候数据是一致的。
3、最终一致性。（弱一致性的升级版，保证在一定时间内达到数据一致）

最终一致性的具体实现包括：
读时修复、写时修复、异步修复。	

总结：ACID是数据库事务的完整性理论，CAP是分布式系统设计理论，BASE是CAP理论中AP方案的延伸。
```

## 9、dubbo+zookeeper的使用有那些好处

```shell
zookeeper基于CP。(可以保证服务的一致性)
```

## 10、注册中心zookeeeper和Eureka的区别

```shell
zookeeper基于CP，一致性，不保证高可用。zookeeper在选举时，或者集群半数以上机器不可用，将无法获得数据。
eureka基于AP，高可用，不保证一致性，即使所以服务机器都挂了，也能拿到本地缓存的数据，不能保证数据是最新的。
```

## 11、MySQL常见的优化方法

```shell
见前面的总结
```

## 12、集合的认识和理解

```shell
集合也叫做容器：有两大接口派生而来，一个是collection接口，一个是map接口。
collection接口主要存单一元素，map存储键值对。
collection下面有三个主要的子接口list、set、queue。

#list、set、queue、map的区别
list：存储的元素有序，可重复（顺序）
set：存储的元素无序，不可重复（独一无二）
queue：存储的元素有序，可重复（排队）
map：键值对，key无序，不可重复。value无序，可重复。

#list
	arrayList:object[]数组，不安全，支持快速访问
	vector：object[]数组，安全
	linkedlist：双向链表，不安全，不支持快速访问
#set
	hashSet：基于hashmap实现，无序、唯一，不安全
	linkedHashSet：是hashset的子类，基于linkedhashmap实现，不安全
	treeset：红黑树（自平衡的排序二叉树），有序、唯一、不安全
#queue
	arrayQueue：object数组 + 双指针
#map
	hashMap：数组+链表+红黑树，不安全，key可以为null，初始16，扩容2n，指定初始值，系统会调整为2的幂次方。
	LinkedHashMap：在hashMap基础上，增加了一条双向链表
	hashTable：数组+链表，安全，key不能为null，初始11，扩展2n+1
	treeMap：红黑树。
	
#collections工具类
常用方法：
1、排序
void reverse(List list)//反转
void shuffle(List list)//随机排序
void sort(List list)//按自然排序的升序排序
void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑
void swap(List list, int i , int j)//交换两个索引位置的元素
//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面
void rotate(List list, int distance)
        
2、查找和替换
//对List进行二分查找，返回索引，注意List必须是有序的
int binarySearch(List list, Object key)
//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)
int max(Collection coll)
//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)
int max(Collection coll, Comparator c)
//用指定的元素代替指定list中的所有元素
void fill(List list, Object obj)
//统计元素出现次数
int frequency(Collection c, Object o)
//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target)
int indexOfSubList(List list, List target)
//用新元素替换旧元素
boolean replaceAll(List list, Object oldVal, Object newVal)

3、同步控制(不推荐，需要线程安全的集合类型时请考虑使用 JUC 包下的并发集合)
synchronizedCollection(Collection<T>  c) //返回指定 collection 支持的同步（线程安全的）collection。
synchronizedList(List<T> list)//返回指定列表支持的同步（线程安全的）List。
synchronizedMap(Map<K,V> m) //返回由指定映射支持的同步（线程安全的）Map。
synchronizedSet(Set<T> s) //返回指定 set 支持的同步（线程安全的）set。


#使用注意事项
1、集合判空
	isEmpty() 时间复杂度为 O(1)。
2、集合转Map
	在使用java.util.stream.Collectors类的toMap()方法转为Map集合时，一定要注意当 value为null时会抛NPE异常。
3、集合遍历
	不要在foreach循环里进行元素的remove/add操作。remove元素请使用 Iterator 方式，如果并发操作，需要对Iterator对象加锁。
	fail-fast机制：多个线程fail-fast集合进行修改时，会抛出ConcurrentModificationException。单线程也有可能出现。
	java.util包下面的所有的集合类都是 fail-fast 的，而java.util.concurrent包下面的所有的类都是 fail-safe 的。
4、集合去重
	利用 Set 元素唯一的特性，可以快速对一个集合进行去重，避免使用List的contains()进行遍历去重或者判断包含操作。
5、集合转数组
	使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一致、长度为 0 的空数组。
6、数组转集合
	使用工具类 Arrays.asList() 把数组转换成集合时，不能使用其修改集合相关的方法， 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。
```

13、平时有没有看博客的习惯，平时下班都喜欢干什么

# 四

1、自我介绍

2、你在项目中的角色

## 3、你对spring和springmvc的认识

```shell
一般说spring框架指的是Spring Framework，它是很多模块的集合，使用这些模块可以很方便的协助我们开发。
Spring最核心的思想就是不重复造轮子，开箱即用。
spring的核心工作主要是ioc 和 aop
spring模块：
	spring core：spring所有功能都需要依赖这个模块，提供IOC依赖注入功能
	spring aop ：提供面向切面的编程实现
	spring tx：提供事务的支持
	spring jdbc：提供数据访问的抽象JDBC。
	spring web：提供web功能的基础支持
	spring webmvc：提供spring mvc的实现
	spring test：提供测试功能的实现

#spring、spring mvc、springboot之间的关系
springmvc 是spring中的一个重要模块，主要赋予spring快速构建mvc架构的web程序能力，
MVC（模型、视图、控制器），核心思想是通过将业务逻辑、数据、显示分离来组织代码，实现功能。

springboot只是简化了配置，如果需要构建mvc架构的web程序，还是需要使用spring mvc作为mvc框架，只是springboot帮助简化了很多spring mvc的配置，真正的做到开箱即用。

#IOC是什么
IOC（控制反转）是一种设计思想。就是将原有的程序创建对象的控制权，交由spring框架来管理。
控制：对象创建的权力
反转：控制权交给外部环境（spring框架、ioc容器）

在spring中，ioc容器是spring用来实现ioc的载体，ioc容器实际上就是个Map（key，value），map存放的是各种对象。

#IOC有什么好处
1、对象间的耦合读依赖程序降低。
2、实例资源更容易管理。

#AOP是什么
AOP（面向切面编程），将与业务无关，却为业务提供公共调用的逻辑封装起来。减少系统重复代码，降低模块耦合读，提供扩展性和可维护性。比如日志管理、事务处理、权限控制等。

AOP是基于动态代理模式实现的，代理对象实现了接口，就用JDK Proxy代理。没有实现接口，就用Cglib代理。

也可以使用AspectJ。Spring AOP集成了AspectJ，AspectJ 可以说是java生态最完整的aop框架。

#Spring AOP 和 AspectJ AOP 有什么区别？
	Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。切面比较少，那么两者性能差异不大。切面太多的话，推荐选择 AspectJ ，它比 Spring AOP 快很多。

#什么是bean
bean代指那些被IOC容器所管理的对象。

#bean的作用域
singleton：唯一的bean实例。默认都是单例
prototype：每个请求创建一个bean实例。
request：每个http请求创建一个bean实例，只在当前http request内有效。
session：每个新session的http请求会创建一个bean实例，只在当前http session内有效。
global-session：全局session作用域。spring 5 已经没有了。

#单例bean的线程安全问题。
单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。
方案：
	1、在bean尽量避免定义可变的成员变量
	2、在类中定义ThreadLocal成员变量，将可变的成员变量保证在ThreadLocal中。
一般情况，bean都是无状态（没有实例变量的），这种情况bean是安全的。

#@Component和@bean的区别
1、@Component作用于类，@Bean作用于方法。
2、@Component通常是通过类路径扫描自动装配到spring容器中。@ComponentScan指定路径
	@bean通常是在标有@bean方法中定义产生这个bean。
3、@bean比@component注解自定义更强。在引用第三方库的类装配到spring容器，只能通过bean实现。

#将一个类声明为bean的注解有那些
@Component
@Respiratory
@Service
@Controller

#bean的生命周期
可参考：https://www.cnblogs.com/zrtqsk/p/3735273.html
实例化bean对象，设置对象属性
是否实现Aware相关接口，调用相关方法

前置处理BeanPostProcessor，执行postProcessBeforeInitialization方法
是否实现InitializingBean初始化bean接口，执行afterPropertiesSer方法
是否配置了自定义的init-method，执行对应方法
后置处理beanPostProcessor，postProcessAfterInitialization方法

bean使用

是否实现disposableBean销毁bean接口，执行destroy方法
是否配置有自定义的destroy方法，执行对应方法

#springmvc
springmvc  采用MVC设计思想，通过将业务逻辑、数据、显示分离来组织代码，帮助我们进行更简洁的web开发。

#springmvc的流程
1、客户端发送请求，请求到dispatcherServlet。
2、dispatcherServlet根据请求信息调用HandlerMapping（处理器映射器），解析请求对应的handler（处理器）。
3、找到handler处理器（也就是我们平常说的 Controller 控制器）后，给handlerAdapter(处理器适配器)处理。
4、handlerAdapter（处理器适配器）调用真正的处理器，处理业务逻辑。
5、处理业务逻辑后，返回一个ModelAndView（数据模型和视图）。
6、viewResolver（视图解析器）查找视图。
7、dispatcherServlet把返回的model（数据模型）传给view（视图）渲染。
8、把渲染的视图给客户端。

#spring用到了那些设计模式
工厂设计模式：beanFactory、application创建bean对象
代理设计模式：aop功能
单例设计模式：bean默认都是单例的
模板方法模式：jdbcTemplate等
观察者模式：事件驱动模型
适配器模式：spring mvc，aop的增强通知

#spring管理事务的方式
编程式事务：通过事务模板或事务管理器，手动管理实现。
声明式事务：xml配置文件、或者注解实现。AOP功能，动态代理模式。

#spring的事务传播行为
1、PROPAGATION_REQUIRED。如果有事务，就加入。没有，就创建一个新的事务。默认行为。
2、PROPAGATION_REQUIRES_NEW。如果有事务，就挂起。创建一个新的事务。两个事务独立，不干扰。
3、PROPAGATION_NESTED。如果有事务，就创建一个嵌套事务。没有，就等价PROPAGATION_REQUIRED
4、PROPAGATION_MANDATORY。如果有事务，就加入该事务。没有，就抛出异常。

===以下传播行为事务不回滚
5、PROPAGATION_SUPPORTS。如果有事务，加入。没有，就以非事务运行
6、PROPAGATION_NOT_SUPPORTED。如果有事务，挂起。以非事务运行
7、PROPAGATION_NEVER。如果有事务，就抛出异常。没有，就以非事务运行

#spring事务的隔离级别
默认是ISOLATION_DEFAULT，使用数据库默认的隔离级别。
mysql是可重复读，oracle是读已提交。
其他的属性值，就是数据库的隔离级别。
1、ISOLATION_READ_UNCOMMITTED ：读未提交
2、ISOLATION_READ_COMMITTED：读已提交
3、ISOLATION_REPEATABLE_READ ：可重复读
3、ISOLATION_SERIALIZABLE：可串行化

#@Transactional(rollbackFor = Exception.class)注解了解吗？
	在 @Transactional 注解中如果不配置rollbackFor属性,那么事务只会在遇到RuntimeException的时候才会回滚，加上 rollbackFor=Exception.class,可以让事务在遇到非运行时异常时也回滚。

#TransactionDefinition:事务属性
	事务管理器接口 PlatformTransactionManager 通过 getTransaction(TransactionDefinition definition) 方法来得到一个事务，这个方法里面的参数是 TransactionDefinition 类 ，这个类就定义了一些基本的事务属性。
事务属性包括5个方面：
	1、隔离级别
	2、传播行为
	3、回滚规则
	4、是否只读：指定事务为只读，不涉及数据修改，数据库会提供一些优化手段。
	5、事务超时：超时该时间未完成，自动回滚。默认-1

#Transactional事务失效的情况
1、@Transactional注解，只有作用到public方法上才生效。
2、@Transactional事务的传播行为设置错误，导致失效。
3、@Transactional事务的回滚规则设置错误，导致失效。
4、同一个类中调用 @Transactional 注解的方法，导致失效。A调用B，A没有声明，B声明。
	AOP动态代理原因，使用AspectJ可解决。
5、异常被catch捕获，导致失效。业务方法一般不需要catch，需要的话一定要抛出异常Throw new 异常。
6、底层使用的数据库不支持事务机制，导致失效。
```

# IOC容器

## 简介

1、最基本启动spring容器例子

```java
public static void main(String[] args) {
    ApplicationContext context = new ClassPathXmlApplicationContext("classpath:applicationfile.xml");
}
```

2、继承关系，大体是

​	applicationContext

​	configurableApplicationContext

​	abstractApplicationContext

​	abstractRefreshableApplicationContext

​	abstractRefreshableConfigurableApplicationContext

​	abstractXmlApplicationContext

​	classPathXmlApplicationContext

3、BeanFactory ，生产bean的工厂，负责生产和管理bean实例。

​	继承关系

​	beanFactory

​		listableBeanFactory  hierarchicalBeanFactory

​		applicationContext

## 启动过程分析

**创建bean容器前准备工作、创建bean容器，加载并注册bean。bean实例化完成。准备bean容器，初始化所有的single bean。**

1、ClassPathXmlApplicationContext 构造方法

2、refresh（）方法。加锁，避免重建refresh（）时，又来一个启动或者销毁容器操作。

​		obtainFreshBeanFactory();加载bean，注册bean容器。

​		解析bean，注册到beanFactory中。bean还未初始化；

​		prepareBeanFactory（）准备bean容器。

​		初始化initMessageSource（）；

​		初始化事件广播器initApplicationEventMulticaster（）；

​		注册事件监听器，registerListeners（）；

​		初始化所有的finishBeanFactoryInitialization（beanFactory） （单例singleton beans）。lazy-init除外。重点

​		最后广播事件，初始化完成finishRefresh（）；



​		遇到异常，销毁初始的beans；destroyBeans();

​		cancelRefresh(ex);throw ex；抛出异常

3、进入obtainFreshBeanFactory（）加载bean，注册bean；

​		进入refreshBeanFactory（）；

​		了解BeanDefinition 封装的bean信息后，

​		DefaultListableBeanFactory beanFactory = createBeanFactory();

​		customizeBeanFactory(beanFactory); //是否允许bean定义覆盖，是否允许bean循环依赖

​		进入loadBeanDefinitions(beanFactory);//根据配置，加载bean，然后放到beanfactory

​		进入loadBeanDefinitions（）；一步步的执行，会看到parseDefaultElement（）和

parseCustomElement（）分支。解析配置分支的节点<import><beans>等。一步步的根据配置注册bean容器。

4、finishBeanFactoryInitialization初始化所有的singleton beans。

​		普通bean，调用getbean（）；

​		创建bean，createBean（）；

​		doCreateBean（）；

​		populateBean（），实例化设值。

​		initializeBean（）处理回调。

# Spring/Spring Boot 常用注解总结

## 1. @SpringBootApplication

springBootApplication是下面三个注解的集合

​	@configuration：需要在spring上下文中注册额外的bean或者导入其他配置类。

​	@componentScan：扫描指定包下面的所有类，找到注解的bean。

​	@enableAutoConfiguration：启用springboot自动配置机制

## 2、@RestController

restController是下面二个注解的集合

​	@Controller：控制层

​	@ResponseBody：返回json或者xml数据

## 3、@Scope

springbean的作用域：

​	singleton、prototype、request、session

## 4、@Configuration

配置类，可以使用@component替代，这些写更语义化。

## 5、@GetMapping

get请求，等价于@RequestMapping（value=”“ ，method=RequestMethod.GET）

类似：@PostMapping、@PutMapping、@DeleteMapping、@PatchMapping

## 6、@PathVariable和@RequestParam

`@PathVariable`用于获取路径参数，`@RequestParam`用于获取查询参数。

```java
@GetMapping("/klasses/{klassId}/teachers")
public List<Teacher> getKlassRelatedTeachers(
         @PathVariable("klassId") Long klassId,
         @RequestParam(value = "type", required = false) String type ) {
...
}
```

## 7、@RequestBody

用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且**Content-Type 为 application/json** 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。系统会使用`HttpMessageConverter`或者自定义的`HttpMessageConverter`将请求的 body 中的 json 字符串转换为 java 对象。

```java
@PostMapping("/sign-up")
public ResponseEntity signUp(@RequestBody @Valid UserRegisterRequest userRegisterRequest) {
  userService.save(userRegisterRequest);
  return ResponseEntity.ok().build();
}
```

**一个请求方法只可以有一个`@RequestBody`，但是可以有多个`@RequestParam`和`@PathVariable`**。 

## 8、@ControllerAdvice和@ExceptionHandler

@ControllerAdvice ：注解定义全局异常处理类

@ExceptionHandler ：注解声明异常处理方法

> 详情链接：https://javaguide.cn/system-design/framework/spring/spring-common-annotations.html

# 四

## 4、Springboot和springcloud的认识

```shell
Springboot的核心是自动封装
#什么是 SpringBoot 自动装配
	springboot定义了一套接口规范：这套规范规定，springboot在启动时会扫描引用jar包中的META-INF/spring.factories文件，将文件中配置的类型信息加载到spring容器。并执行类中定义的各种操作。对于外部jar来说，只需要按照springboot定义的标准，就能将自己的功能装置进springboot。
	自动装配就可以理解为，通过注解或者一些简单的配置就能在springboot的帮助下实现某块功能。


#实现流程
通过springbootApplication注解集合。
	@EnableAutoConfiguaration：实现自动装配的核心注解
	上面注解类导入AutoConfigurationImportSelector:加载自动装配类
	AutoConfigurationImportSelector 类实现了 ImportSelector接口，重写selectImports（），该方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中。
	selectImports方法中：getAutoConfigurationEntry（）主要负责加载自动配置类。
	getAutoConfigurationEntry（）方法流程：
		1、判断自动装配是否打开。默认打开
		2、获取EnableAutoConfiguration注解的
		exclude：根据类排除指定的自动配置
		excludeName：根据类名排除指定的自动配置
		3、获取需要自动装配的所有配置类，读取所有导入的META-INF/spring.factories文件。
		4、筛选满足条件的配置
		
总结：Spring Boot 通过@EnableAutoConfiguration开启自动装配，通过 SpringFactoriesLoader 最终加载META-INF/spring.factories中的自动配置类实现自动装配，自动配置类其实通过@Conditional按需加载的配置类，使其生效必须引入spring-boot-starter-xxx包实现启动依赖。

#springcloud是什么
下面基于Spring Cloud Netflix 

springcloud就是微服务系统架构的一站式解决方案，构建微服务中需要的服务发现和注册、配置中心、负载均衡、熔断器等操作，springcloud为我们提供了一套简易的编程模型，我们能在springboot的基础上轻松实现微服务项目的构建。
注册中心：eureka
负载均衡：ribbon
	轮询算法：
	RoundRobinRule：轮询策略，Ribbon 默认采用的策略。若经过一轮轮询没有找到可用的 
	provider：最多轮询 10 轮。若最终还没有找到，则返回 null
	RandomRule：随机策略，从所有可用的 provider 中随机选择一个。
	RetryRule：重试策略。先按照 RoundRobinRule 策略获取 provider，若获取失败，则在指定的时限内重试。默认的时限为 500 毫秒。
	还可以自定义负责均衡算法。
	顺便提一下nginx轮询算法：
		轮询和加权轮询算法。
服务调用：Open Feign
熔断和降级：Hystrix
网关：Zuul
	实现限流：令牌桶限流
	实现权限校验
微服务统一配置中心：Config 
消息总线：bus
```

# Springboot自动装配原理

```shell
#自动装配本质：https://mp.weixin.qq.com/s/f6oED1hbiWat_0HOwxgfnA  好文

	1、springboot的自动装配本职就是通过spring去读取meta-inf/spring.factories中保存的配置类文件，然后加载bean定义的过程。
	2、如果是标了@Configuration注解，就批量加载里面的bean定义。
	3、如何实现自动，就是通过配置文件获取对应的批量配置类，然后通过配置类批量加载bean定义，只要有写好的配置文件spring.factories就实现了自动。
	
#流程 https://blog.csdn.net/weixin_40388441/article/details/108875756
1、@SpringBootApplication中
2、@EnableAutoConfiguration注解

...
@Import({AutoConfigurationImportSelector.class})关键
public @interface EnableAutoConfiguration {
	//定义的一个常量，用于覆盖开启/关闭自动配置的功能。
    String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration";
    //根据类排除指定的自动配置
    Class<?>[] exclude() default {};
    //根据类名排除指定的自动配置
    String[] excludeName() default {};
}
...
3、@import注解启动该类
AutoConfigurationImportSelector 中 selectImports方法被调用
-->检查自动配置是否开启-->加载类路径下的原始数据配置-->加载spring.factories中EnableAutoConfiguration配置类-->配置类去重-->获得被排除类集合-->检查排除的类是否合法-->配置类集合中去除被排除的类-->过滤自动加载组件-->将配置类和排除类通过事件传入监听器中-->返回自动配置类全限定名数组

小结：SpringBoot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，并将这些值作为自动配置类导入容器，自动配置类便会生效进行自动配置的工作，它会给容器中导入非常多的自动配置类 （xxxAutoConfiguration），简单来说就是给容器中导入这个场景需要的所有组件，并配置好这些组件，免去了我们手动编写配置注入功能组件等的工作。

run方法：实例化SpringApplication类。
流程：
	获取springApplicationlistener监听器-->启动获取到的所有监听器-->初始化ConfigurableEnvironment-->打印banner图标-->创建容器configurationApplicationContext-->准备容器-->初始化容器-->监听器通知容器启动完成-->监听器通知容器正在运行
	
小结：
	获取监听器和参数配置
	打印Banner信息
	创建并初始化容器
	监听器发送通知
```

# 四

## 5、MySQL有那些索引，MySQL你平时的优化的处理方法

```shell
查看上面
```

## 6、Nacos注册中心的好处和其他注册中心的区别

```shell
Nacos服务注册需要的能力：
	1、服务提供者把自己的协议地址注册到Nacos server
	2、服务消费者需要从Nacos server上去查询服务提供者的地址
	3、Nacos Server感知服务提供者的上下线的变化
	4、服务消费者需要动态感知到Nacos Server端服务地址的变化
	
	服务注册：注册中心服务端，有一个用来管理服务的容器。可以是内存的map、mysql数据库等。注册成功后，提供者和注册中心维持心跳，心跳机制保证注册中心可以及时剔除失效的实例。
	服务发现：两种，一是消费者直接向注册中心发送获取某个实例请求。二是，消费者向服务中心订阅某个服务，并提交一个监听器，当注册中心服务发生变更时，监听器收到通知。消费者更新本地服务实例列表，保证服务都是可用的。
	负载均衡：轮询法、随机法、对请求hash后取模等。nacos是随机获取方法。
	
#nacos服务分为客户端和服务端
客户端：
	启动时，从服务端读取指定服务名称的实例列表，缓存到本地。每隔10秒向服务端轮询一次服务列表。
服务端：
	通过心跳检测，发现服务提供者的心跳超时，push消息给消息端，（消费者会基于udp协议建立一个监听，一旦接收到服务端传来的数据，就会更新本地缓存）。
	
总结：
1、nacos = springcloud注册中心 + springcloud配置中心
2、nacos是阿里开源的，nacos支持基于DNS和解压RPC服务的发现
3、nacos只需要简单的配置就可以完成服务的发现和注册
4、nacos支持动态配置服务，可以一中心化、外部化、动态化的方法管理环境的应用配置和服务配置。
5、nacos功能更加丰富，社区活跃，界面美观。

区别：
nacos支持可以支持CP/AP切换，默认AP
```

## 7、MQ消息发送使用场景有那些，如果消息发送失败了怎么办，重发了怎么办，服务器宕机了，消息未发送怎么办

```shell
#为什么用消息队列
1、异步处理提供系统性能，减少响应所需的时间。
2、削峰/限流，短时间高并发产生的请求事务存储到消息队列中，避免直接把后端服务打垮掉。
3、解耦降低系统的耦合性

#带来的问题
1、系统可用性一定程度降低，需要考虑MQ挂掉，和消息丢失问题。
2、系统的复杂性提高，需要考虑消息是否重复消息、处理消息丢失情况、消息的顺序性问题。
3、一致性问题，异步处理，消息没有消息，导致服务数据不一致。


#AMQP支持的消息模型五种
1、direct exchange
2、fanout exchange
3、topic change
4、headers exchange
5、system exchange

#如何解决顺序消费问题
RabbitMQ不能保证消息顺序，如果要保证顺序，只能在业务方做出来。比如在消息体内增加全局唯一标识来实现，让同一标识的在同一个队列中。

#重复消费--幂等问题
1、通过写入到redis来保证，redis的key和value形式，天然支持幂等性。
2、消息体增加业务唯一id，作为去重的意见，避免同一ID多次消费。
3、记录消息状态字段，更加这个字段来判断是否已经消费。或者使用一个集中式的表，来存储消息的消费状态。


#消息发送失败
	使用ACk机制，
	
#服务宕机
	开启持久化、部署镜像服务
	
#消息堆积问题
	后台定时删除没有旧的不使用的消息信息。
	更加业务实现不同，丢弃不必要的任务。

#RabbitMQ交换器的类型
fanout：发送到该Exchange的消息路由到所有与它绑定的Queue中，不需要做任何判断操作。	
direct：把消息路由到那些 Bindingkey与RoutingKey 完全匹配的 Queue 中。
topic：把消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，可定义匹配规则。
headers：headers类型的交换器不依赖于路由键的匹配规则来路由消息，根据发送的消息内容中的 headers 属性进行匹配。不推荐。

#如何保证正确发送到RabbitMQ，确保消息接收方消息了消息
发送方确认模式，在所有信道上发布消息指定一个唯一的ID，发送到目的队列后，返回一个确认为发送方（包含唯一ID）。
接收方确认机制，消费者接收到消息后，确认（接收和确认不同）。确认消息后，RabbitMQ才从队列删除消息。

#消息如何分发
队列有一个消费者订阅，以循环的方式发给消费者。

#RabbitMQ消息类型
基本消息模式：一对一
work消息模式：多个消费者绑定一个队列，共同消费队列中的信息。
订阅模式：fanout 广播
订阅模式：direct 定向
订阅模式：topic 通配符
```

# RabbitMQ

## 1、AMQP协议

主要概念：

Message（消息)：处理数据的原子单元，包括内容头、属性、内容体。

producer（消息生产者）：发布消息的客户端程序。

exchange（交换机）：接收消息，并将消息路由给队列。

bingind（绑定）：消息队列和交换器之间的关联。

virtual host（虚拟主机）：消息队列以及相关对象的集合。本质是缩小版的实例，提供自己的队列、交换器、绑定和权限机制。

broker（消息代理）：消息代理，实现消息队列和路由功能的过程。

Routing key（路由规则）：确定如果路由的一个特定消息。

Queue（消息队列）：消息的容器。

connection（连接）：客户端和消息队列服务器之间的TCP连接。

Channel（信道）：AMQP命令是通过信道发出去的。客户每一个线程都需要与消息服务器建立交互，每一个线程都建立一个TCP连接，TCP连接浪费，操作系统也会承受不住这么多压力，信道可用复用一个TCP连接。

Consummer（消息消费者）：从消息队列中取到消息的客户端应用程序。

## 2、RabbitMQ特点

可靠性、灵活的路由功能、支持消息集群，高可用性、支持多种协议、支持多语言、提供管理界面、提交跟踪机制、提供插件机制

## 3、连接

1、连接，Connection可用创建多个channel实例，但是channel实例不能线程间共享，应用程序为每一个线程开辟了一个channel。

2、使用交换机和队列，declare：声明的意思。

​	channel.exchangeDeclare();； 创建交换机

​	channel.queueDeclare().getQueue()； 创建队列

​	channel.queueBing()；进行绑定

2.1 declareExchange(Exchange exchange) 创建交换机

```java
public interface Exchange extends Declarable {
    //交换机名称
    String getName();
	//交换机类型 常见的
    //fanout：广播，将消息交给所有绑定到交换机的队列。
   	//direct：定向匹配，把消息交给符合指定routing key 的队列。
    //topic：通配符匹配，把消息交给符合routing pattern（路由模式） 的队列
    String getType();
	//是否持久化
    boolean isDurable();
	//是否自动删除
    boolean isAutoDelete();
	//其他参数
    Map<String, Object> getArguments();
	//是否延迟
    boolean isDelayed();
	//是否内置
    boolean isInternal();
}
```

2.2 queueDeclare()创建队列

```java
public class Queue extends AbstractDeclarable implements Cloneable {
    //....
    //队列名称
    private final String name;
    //队列持久化
    private final boolean durable;
    //是否排它
    private final boolean exclusive;
    //是否自动删除
    private final boolean autoDelete;
    //...
    //其他参数
    super(arguments);
}
```

2.3declareBinding（）绑定

```shell
queue：队列名称
exchange：交换机名称
routingkey：绑定队列和交换机的路由键
argument：其他参数
```

## 4、发送消息

basicPublish（）；

```shell
String exchange：交换机名称
String routingKey：路由键
BasicProperties props：消息的基本属性
byte[] body：消息体
```

## 5、消费消息

push模式（推）：采用basicComsume进行消息

pull模式（拉）：采用basicGet进行消息

basicComsume（）方法：

```shell
queue:队列名称
autoAck：是否自动确认
comsumerTag：消费者标签，区分多个消费者
noLocal：自己消费，自己生产
exclusive：是否排它
argument：其他参数
callback：回调函数
```

basicGet（）方法

只想从队列获得单条消息而不是持续订阅，就是有pull模式，要实现高吞吐量，消费者应是有push模式。

## 6、消息确认与拒绝

​	RabbitMQ提供消息确认机制，当订阅队列是，指定**autoAsk为false**时，RabbitMQ会等待消费者回复确认信息后，才从内存（或者磁盘）中删除。**autoAsk为true**时，不管消费者是否消息到，MQ发送后就直接内存（或者磁盘）中删除。

​	消息收到消息，拒绝而不是确认，调用basicReject（）方法。拒绝有两个，设置requeue的值，false那消息队列发送给其他相同的消息者，true是直接从队列移除，不发送给新的消费者。

## 7、关闭连接

## 8、死信队列

一般有下面三种情况：消息被拒绝（不能重新进入队列）、消息过去、队列达到最大长度

出现死信后，RabbitMQ会自动把消息发送到死信交换器（DLX）上。

## 9、持久化

交换机持久化、队列的持久化、消息的持久化。

持久化中宕机怎么办，使用配置的镜像队列，提高可靠性。

```shell
#怎样避免消息丢失：
	消费者ACK机制，防止消息丢失。
	上面的持久化，
	要将消息持久化，前提是：队列、交换机都持久化
```

## 10、生产者确认

1、事务机制：事务机制影响性能和效率。

2、发送方确认机制：将信道设置未confim（确认）模式，进入改信道的消息都有指派一个唯一的ID，消息被投递到所指派的队列后，RabbitMQ就会发送一个确认（ack）给生产者。持久化开启后，消息会在持久化成功后发出。

# 四

## 8、说一下springcloud常用的组件库有那些，各自的用途

```shell
Eureka: 服务发现框架
Ribbon： 进程内负载均衡器
Open Feign： 服务调用映射
Hystrix： 服务降级熔断器
Zuul： 微服务网关
Config： 微服务统一配置中心
Bus： 消息总线
```

## 9、MySQL行和列逆转的函数有使用过嘛

```shell
行转列一般通过GROUP_CONCAT函数来实现
```

## 10、ES的使用场景，谈一下你对它延迟和原理的认识

```shell
ES功能:
1、分布式的搜索引擎和数据分析引擎
2、全文检索、结构化检索、数据分析
3、对海量的数据进行近实时的处理
使用场景：
1、非结构化的数据查询
2、海量数据的快速检索
3、日志数据分析，logstash采集日志，ES进行复杂的数据分析
```

## 11、Redis的使用，热点数据，一般你使用在那些地方

```shell
查看上面
```

## 12、你工作中微服务的项目是怎么模块划分的

```shell
https://blog.csdn.net/w1014074794/article/details/122619856
	
功能性方面（ DDD 的理论知识，功能维度主要是划分清楚业务的边界）
	公共业务模块、单一职责模块。
	1、找出领域实体和值对象等领域对象。
	2、找出聚合根，根据实体、值对象与聚合根的依赖关系，建立聚合。
	3、根据业务及语义边界等因素，定义限界上下文。
	4、每一个限界上下文可以拆分为一个对应的微服务，但也要考虑一些非功能因素。
	
非功能性方面：
	拓展性、复用性、高性能、高可用、安全性、异构性
```

# 五

1、自我介绍

2、讲一下你工作中遇到的问题，怎么处理的

## 3、springboot的自动装配是怎么装配的

```shell
1、springboot启动的时候加载主配置类，开启自动配置功能@EnableAutoConfiguration注解
2、@EnableAutoConfiguration注解
	利用EnableAutoConfigurationImportSelector类给容器导入一些组件
	selectImports()方法中，去获取需要加载的配置。
	扫描jar路径下的META-INF/spring.factories
	将配置文件里面配置的EnableAutoConfiguration的值加入到了容器中；用他们来做自动配置。
3、每一个自动配置类进行自动配置功能。
4、所有在配置文件中能配置的属性都是在XXProperties类中封装，配置文件可以配置什么可以查看对应的属性类。

@Conditional定义什么情况下配置的内容生效
```

## 4、接口幂等性怎么处理的

```shell
1、token机制
	1、客户端先发送一个请求获取token，服务器端生成一个全局唯一ID作为token保证到redis中，然后把这个id返回给客户端。
	2、客户端调用业务请求，携带这token
	3、服务端校验token，校验成功，执行业务，并删除redistoken。
	4、校验失败，说明redis中没有token，属于重复操作，直接返回结果给客户端。
	
2、基于数据库实现
	1、建议一个去重表，其中某个字段建立唯一索引。
	2、客户端请求服务端，服务端将这信息插入去重表。
	3、表有唯一索引，插入成功。就执行业务
	4、插入失败，说明已执行，直接返回。
	
3、基于redis实现
	setnx命令：setnx key value.将key值设为value
	如果key存在，setnx不执行动作。设置成功是返回1，失败返回0
	
	1、客户端请求服务器，服务器拿到业务的唯一字段。
	2、将字段以setnx方式存入redis，并根据业务情况设置的超时时间。避免占用内存。
	3、设置成功，证明这是第一次请求，执行后续逻辑。
	4、设置失败，代表已执行，直接返回。
	
4、状态控制
	如果业务有不同的状态，判断数据状态执行后续操作。

5、乐观锁
	数据库增加版本号字段，每次更新根据版本号来判断。

```

## 5、redis日常使用的类型，什么业务下使用的

```shell
1、热点数据缓存 string类型
2、分布式锁 string类型setnx命令，不存在才成功
3、全局ID，分库分表，一次性取一段
4、计数器 incr方法
5、限流
6、位统计 bitcount
7、商品筛选、共同关注（交集）
8、排行榜
```

## 6、注册中心了解那些，NACOS默认是什么

```shell
Eureka、zookeeper、nacos
nacos默认：AP  可用性
```

## 7、synchronize锁Integer会有什么问题

```shell
//https://blog.csdn.net/qq_33371766/article/details/123082938

对于 Integer，当值在缓存范围内的时候，会返回同一个对象。当超过缓存范围，每次都会 new 一个新对象出来。这个过程会涉及到拆箱和装箱的过程，这个过程中会调用到 Integer.valueOf 方法。导致锁的对象发现变化。
```

## 8、日常使用锁，是怎么使用的

```shell
查看锁的说明
```

## 9、熔断和限流和降级

```shell
限流：限制请求的数量，限制某段时间内的请求总量。

熔断：一个上游服务，可能调用多个下游服务。如果下游服务出现了故障，上游服务还是继续访问的话，就可能回出现请求无法被解决，被堆积的情况。熔断器可以防止服务不断的去尝试下游可能超时或失败的服务，即时断开这条链路。

降级：如何在资源有限的情况下，扛住海量的请求（弃卒保帅）。降低某些服务质量（例如降低图片分辨率），或者禁用一些服务。
```

## 10、类的加载过程，每一步做了什么

```shell
https://baijiahao.baidu.com/s?id=1666673832314942035
#类的生命周期
加载--连接--初始化--使用--卸载
连接又可分为：验证--准备--解析

#类加载过程
加载--连接--初始化
连接又可分为：验证--准备--解析

#加载
	1、获取类的二进制文件。
	2、二进制文件转运行时的数据结构。
	3、生成类的class对象。
#连接
	#验证
		1、文件格式验证：class文件格式验证
		2、元数据验证：字节码语义分析
		3、字节码验证：验证方法是否正常
		4、符号引用验证：验证引用是否有访问权限
	#准备
		为类静态变量分配内存并赋初始值
	#解析
		虚拟机将常量池的符号引用替换成直接引用的过程
#初始化
	执行类构造器<clinit>()方法的过程。clinit方法是在编译后自动生成的。clinit方法过程就是用户在类中定义的静态变量赋值、静态代码块执行过程。准备阶段是初始值，这里是设置成用户定义的值。比如 public static int i = 5；准备阶段是0，这里赋值为5
	
注意：过程不全是按照固定流程进行，加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。

#使用

#卸载
表示类对象被GC，卸载类满足3个条件
1、该类所有的实例都已被GC，堆上不存在该类的实例对象。
2、该类没有在其他地方被引用
3、该类的类加载器实例已被GC

注意：在JVM生命周期中，jvm自带的类加载器加载的类不会被卸载的。我们自定义的加载器加载类的可能被卸载。
jdk字段的BootStrapClassLoader、ExtClassLoader、AppClassLoader负责加载jdk提供的类，所以它们(类加载器的实例)肯定不会被回收。

```

### 10扩展1：类加载器

```shell
#java内置了三个重复的类加载器：
1、bootStrapClassLoader(启动类加载器)：/lib下或者xbootclasspath参数指定下的类
2、ExtensionClassLoader(扩展类加载器)：/lib/ext下的类或java.ext.dirs系统变量指定下的类
3、appClassLoader(应用程序类加载器)：加载当前应用classpath下的类

#双亲委派机制
每一类都有对应的加载器。加载器在工作时使用双亲委派机制加载。
从启动类、扩展类、应用程序类、用户自定义类，从下往上看是否加载，从上往下尝试加载。

#双亲委派的好处
双亲委派保证了java程序的稳定，避免类的重复加载，同时核心的API不被篡改。

#如何打破双亲委派机制
自定义加载器继承classLoader，
	不想打破双亲委派，重写classloader类的findclass()方法。
	想打破双亲委派，重写classloader类的loadClass()方法。
```

### 10拓展2：重要的jvm参数

```shell
#堆内存相关
虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。

指定堆内存大小:-Xms和-Xmx
指定新生代内存大小:-XX:NewSize和-XX:MaxNewSize或者-Xmn（表示前面两个参数一致） 
指定元空间大小：MetaspaceSize和MaxMetaspaceSize，元空间使用的是本地内存

```

## 11、mysql的隔离级别有那些，mysql默认是什么

```shell
四种：读未提交、读已提交、可重复读、串行化。
默认是可重复读。
```

## 12、怎么解决缓存和数据库不一致的问题

```shell
https://mp.weixin.qq.com/s/Fp4rswunl9Xoe_BoWHow6g

https://mp.weixin.qq.com/s/sh-pEcDd9l5xFHIEN87sDA

https://mp.weixin.qq.com/s/olmqhogDIW1dE3_RwQ78Bg

#更新缓存方案
1、先更新缓存，后更新数据库
2、先更新数据库，后更新缓存

#删除缓存方案
1、先删除缓存，后更新数据库
2、先更新数据库，后删除缓存

先删除缓存，后更新数据库，当发生「读+写」并发时，还是存在数据不一致的情况。
先更新数据库，后删除缓存，发现的概率很低：
需要满足下面的场景：
	1、缓存刚好失效
	2、读请求+写请求并发
	3、更新数据库+删除删除的时间，要比读数据库+写缓存时间短。
	因为写数据库一般会先「加锁」，所以写数据库，通常是要比读数据库的时间更长的。

#第二步失败问题
	1、重试
	2、异步重试，可靠性引入MQ
	3、订阅数据库变更日志，再操作缓存。中间件，例如阿里的canal，mysql数据修改时，会产生一条变更日志binlog

总结：想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。

#缓存延迟双删策略
在线程删除缓存、更新完数据库之后，延时一会，再「删除」一次缓存。


#做到强一致性
加锁/分布式锁。

总结：
采用最终一致性方案，强一致性引入分布式锁。
双删策略，解决并发变更问题。延时时间要大于线程读取数据库+写入缓存的时间。
删除失败场景下采用重试机制，定义重试次数。
如果还是失败，将错误写入重试表，可以定时任务查找表重试。
消息队列MQ重试删除，mysql的binlog日志监听操作。



#3种常用的缓存读写策略
1、旁路缓存读写策略，适合读请求比较多的场景
	写：先更新数据库，然后直接删除缓存。
	读：读取缓存就返回，读取不到就从数据库中读数据返回，然后把数据放到缓存中。
问题1、写数据过程中，可以先删除缓存，后更新数据库嘛？
	不行，因为这样会造成数据库和缓存不一致。
	比如请求1先写数据，这时请求2读数据，缓存删除了，请求2读取数据库的值，读后，请求1更新数据。

问题2、写数据过过程中，先更新DB，再删除缓存不是一样有这个问题嘛？
	理论上会出现，不过因为缓存的写入比数据库的写入速度快，这个概率就非常小。

缺点：
	1)、首次请求数据不在缓存中
		解决方法：
			将热点数据提取放入缓存中
	2)、写操作频繁，会导致cache被频繁删除，影响缓存命中率。
		解决方法：
	 		强一致场景：更新数据库的时候同时更新缓存，同时加锁保证更新cache时不存在线程安全问题。
			允许短暂不一致场景：更新数据库同样更新缓存，但是给缓存加短暂的过期时间。

2、读写穿透，把缓存当做主要数据存储。平时很少用
	写：先查缓存，缓存不存在，直接更新数据库。缓存存在，更新缓存，然后缓存服务自己去更新数据库。（同步更新缓存和数据库）
	读：从缓存读，读到就返回。读不到，先从数据库加载，写到缓存中，再返回。

3、异步缓存写入，
	读写穿透类型，都是缓存服务负责缓存和数据库的读写。
	不同的是，异步缓存写入是异步批量的方式更新数据库。对于一些数据经常变更，一致性要求不高的场景。流量量、点赞量。

```

## 13、redis持久化的方式和区别

```shell
RDB：创建某个时间点上的内存副本
	RDB丢失的数据，将根据用户创建的备份规则。丢失上次备份到宕机时间段的数据。
	默认是此方式：满足一个就会执行bgsave
		15分钟内，有1个key发生变化。触发bgsave
		5分钟内，有10个key发生变化，触发bgsave
		1分钟内，有10000个key发生变化，触发bgsave
AOF：通过最近命令的方式，追加文件内容
	always：有数据修改就写入aof文件
	everysec：每秒同步一次
	no：系统决定何时同步
	aof基于不丢失数据，根据AOF持久化方式，选择everysec 只会丢失一秒内的数据。
	
RDB
缺点：
	一定间隔备份，redis服务宕机，丢失最后一次备份后的数据修改。
	子进程备份时，内存数据被克隆了一份，大致两边的膨胀内存需要考虑。
优点：
	非常紧凑的文件，文件大小比AOF小
	恢复大的数据集，比AOF快
AOF
缺点：
	文件比RDB大，恢复速度满意RDB
	同步运行效率慢于RDB，设置为no，同步效率和RDB相同
优点：
	根据选择的同步方式，每秒记录情况，只会丢失一秒钟数据。

根据使用持久化需求选择
```

### 13拓展1：缓存雪崩、缓存穿透、缓存击穿

```shell
#缓存雪崩	
	一种是：redis可用，缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。
	一种是：redis服务不可用，造成的请求直接落在数据库。
	解决方案：
		1、redis服务不可用情况，采用Redis集群方案。
		2、限流
		3、数据预热
#缓存穿透
	用户想要查询一个数据，发现redis内存数据库没有，也就是缓存没有命中，于是向持久层数据库查询。当用户很多的时候，缓存都没有命中，于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。
	解决方案：
		1、缓存空对象，缓存和数据库都查不到某个 key 的数据就写一个空对象到 Redis 中去并设置过期时间。
		2、布隆过滤器，布隆过滤器是一种数据结构，对所有可能查询的参数布隆过滤器形式存储，布隆控制器存在就执行，不存在就丢弃，从而避免了对底层存储系统的压力；

#缓存击穿
	缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
	解决方案：
		1、设置热点数据不过期
		2、加互斥锁
```

### 13拓展2：内存淘汰机制

```shell
1、设置过期时间的数据中，挑选最少使用的淘汰
2、设置过期时间的数据中，挑选要过期的数据淘汰
3、设置过期时间的数据中，任意选择数据淘汰
4、挑选最少使用的淘汰（常用）
5、任意选择数据淘汰。
6、禁止写入数据。
7、设置过期时间的数据中，挑选最不常用的数据淘汰。
8、挑选最不常用的数据淘汰。
```

14、是否带过团队

## 15、spring的怎么加载，注册的

```shell
#bean的生命周期
可参考：https://www.cnblogs.com/zrtqsk/p/3735273.html
实例化bean对象，设置对象属性
是否实现Aware相关接口，调用相关方法

前置处理BeanPostProcessor，执行postProcessBeforeInitialization方法
是否实现InitializingBean初始化bean接口，执行afterPropertiesSer方法
是否配置了自定义的init-method，执行对应方法
后置处理beanPostProcessor，postProcessAfterInitialization方法

bean使用

是否实现disposableBean销毁bean接口，执行destroy方法
是否配置有自定义的destroy方法，执行对应方法

#加载注册过程看上面
```

## 16、你设计一下出现接口幂等性的解决方案

```shell
1、token机制
	1、客户端先发送一个请求获取token，服务器端生成一个全局唯一ID作为token保证到redis中，然后把这个id返回给客户端。
	2、客户端调用业务请求，携带这token
	3、服务端校验token，校验成功，执行业务，并删除redistoken。
	4、校验失败，说明redis中没有token，属于重复操作，直接返回结果给客户端。
	
2、基于数据库实现
	1、建议一个去重表，其中某个字段建立唯一索引。
	2、客户端请求服务端，服务端将这信息插入去重表。
	3、表有唯一索引，插入成功。就执行业务
	4、插入失败，说明已执行，直接返回。
	
3、基于redis实现
	setnx命令：setnx key value.将key值设为value
	如果key存在，setnx不执行动作。设置成功是返回1，失败返回0
	
	1、客户端请求服务器，服务器拿到业务的唯一字段。
	2、将字段以setnx方式存入redis，并根据业务情况设置的超时时间。避免占用内存。
	3、设置成功，证明这是第一次请求，执行后续逻辑。
	4、设置失败，代表已执行，直接返回。
	
4、状态控制
	如果业务有不同的状态，判断数据状态执行后续操作。

5、乐观锁
	数据库增加版本号字段，每次更新根据版本号来判断。
```

## 17、拓展java内存模型（JMM）

```shell
#JMM模型
	JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。JMM定义了线程和主内存之间的抽象关系，线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

#并发编程的三个重要特性
1、指令重排序
	代码在执行的过程中的先后顺序。
	包括编译器优化重排序、指令级并行重排序、内存系统重排序
2、内存可见性
	当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。
3、原子性
	一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。
	 

```

## 17、高并发场景下的数据怎么处理，怎么保证一致性

```shell
#java对并发的约束
	volatile：保证可见性、禁止指令重排，不能保证原子性。
	提供：synchronized关键字、volatile关键字、ReentrantLock同步锁、atomic工具包、ThreadLocal等等。

1、volatile关键字
	保证读写的都是主内存的变量，且不会对该关键字修饰的变量进行指令重排序，可以保证可见性和有序性。
2、synchronized关键字
	synchronized可以保证可见性、有序性和代码块的原子性。加锁操作
3、ReetranLock同步锁
	互斥重入锁，和synchronized相比，可以等待可中断、使用公平锁、给锁绑定条件。
4、atomic原子类工具包	
5、ThreadLocal工具类
	ThreadLocal提供了线程内存储变量的能力，这些变量不同之处在于每一个线程读取的变量是对应的互相独立的。
6、加锁操作
```

## 18、spring cloud的组件都有哪些，都有什么用

```shell
spring cloud Netflix:
    1、Eureka注册中心，实现服务治理；
    2、Ribbon负载均衡，主要提供客户侧的软件负载均衡算法；
    3、Hystrix断路器，保护系统，控制故障范围；
    4、Zuul，api网关，路由，负载均衡等多种作用；
    5、Config配置管理。
    
springcloud Alibaba:
	nacos：主要的功能有注册中心和配置中心。
	sentinel：从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。
	seata：提供高性能和简单易用的分布式事务服务。
	Spring Cloud Gateway：高性能异步非阻塞网关
	RocketMQ：高性能、高可靠的消息中间件

https://blog.csdn.net/u011212394/article/details/115250745
```

## 19、MQ知道那些，rabbit MQ的几种方式

```shell
看上面的MQ
```

## 20、ps自己加的：RPC是什么，原理是什么

```shell
RPC：远程过程调用
1、客户端以本地调用的方式调用远程服务
2、客户端Stub（桩、存根）接收调用后，负责将方法、参数等序列化：RpcRequest
3、客户端stud找到远程服务地址，发送消息给服务端。
4、服务端stud，收到消息反序列化为对象,RpcRequest
5、服务端stud，根据反序列内容调用本地的方法
6、服务端处理本地方法。
6、服务端stud，得到本地方法执行结果，序列化结果发送到客户端。RpcResponse
7、客户端stud，接收到消息反序列化。RpcResponse
8、客户端得到结果

总结就是：RPC让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。
常见的RPC：
	RMI（JDK自带）、Dubbo、webService...
	
#有http，为啥还用RPC
RPC只是一种设计而已，解决不同服务之间的调用，包含传输协议和序列化协议这两个。
http是一种协议，RPC框架可以使用 HTTP协议作为传输协议也可以直接使用TCP作为传输协议，
使用不同的协议适应不同的场景。

RPC框架功能更齐全，成熟的RPC框架还提供了服务自动注册与发现，负载均衡、可视化的治理和运维、运行期间流量调度等功能。
```

## 21、sentinel的工作原理

```shell
sentinel定位流量控制、熔断降级，主要是控制 QPS 和并发线程数

#Sentinel 的数据统计，采用了滑动窗口的设计

#限流策略
资源名：唯一名称、默认请求路径
针对来源：可以针对调用者限流
流控规则：
	QPS：每秒的请求数量，
	线程数：
是否集群：
流控模式：
	直接：api达到限流条件，直接限流
	关联：关联的资源达到阈值，就限流自己
	链路：资源从那个入口过来的流量，达到阈值，限流。api级别的针对来源
流控效果：
	快速失败 ：直接失败，跑异常
	warm up：进过预热时长，才达到设置的QPS阈值，默认3秒。慢慢的放流量进来
	排队等待：匀速等待，漏桶算法

#降级策略
平均响应时长超过阈值，触发降级（熔断），等待时间窗口结束
异常比例超过阈值，触发降级（熔断），等待时间窗口结束
异常数超过（分钟统计）阈值，触发降级（熔断），等待时间窗口结束

#热点限流
对经常访问的数据QPS模式限流。

#系统规则是从应用级别的入口流量进行控制
单机的负荷、CPU使用率、平均RT（响应时间）、并发线程数、入口QPS

#源码分析
https://www.javadoop.com/post/rate-limiter
https://blog.csdn.net/qq_41547955/article/details/121942557

entryWithPriority（）方法：
lookProcessChain（）方法：
	Sentinel 的处理核心都在这个责任链中，链中每一个节点是一个 Slot 实例，这个链通过 BlockException 异常来告知调用入口最终的执行情况。
	
对于相同的 resource，使用同一个责任链实例，不同的 resource，使用不同的责任链实例。	
public ProcessorSlotChain build() {
        ProcessorSlotChain chain = new DefaultProcessorSlotChain();
        chain.addLast(new NodeSelectorSlot());
        chain.addLast(new ClusterBuilderSlot());
        chain.addLast(new LogSlot());
        chain.addLast(new StatisticSlot());
        chain.addLast(new AuthoritySlot());
        chain.addLast(new SystemSlot());
        chain.addLast(new FlowSlot());
        chain.addLast(new DegradeSlot());
        return chain;
    }
    
 外部请求-->
NodeSelectorSlot：调用链路构建插槽
ClusterBuilderSlot：集群簇点构建插槽
LogSlot：记录插槽
StatisticSlot：数据统计监控插槽
ParamFLowSlot：热点数据插槽
AuthoritySlot：权限控制黑白名单插槽
SystemSlot:系统保护插槽
FlowSlot：核心，流量控制插槽
DegradeSlot：熔断降级插槽


Sentinel 中的流控
	RateLimiterController：排队等待，它通过使用 latestPassedTime 属性来记录最后一次通过的时间，然后根据规则中 QPS 的限制，计算当前请求是否可以通过。
	举例：设置 QPS 为 10，那么每 100 毫秒允许通过一个，通过计算当前时间是否已经过了上一个请求的通过时间 latestPassedTime 之后的 100 毫秒，来判断是否可以通过。假设才过了 50ms，那么需要当前线程再 sleep 50ms，然后才可以通过。如果同时有另一个请求呢？那需要 sleep 150ms 才行。
	WarmUpController：预热，突发流量迅速上升，导致系统负载严重过高。数据库需要建立连接、需要连接到远程服务等，这就是为什么我们需要预热。令牌数来标识当前系统处于什么状态，根据时间推进一直增加令牌，根据通过的 QPS 一直减少令牌
	WarmUpRateLimiterController：预热加排队等待。

#sentinel限流效果算法
	默认：滑动时间窗口算法
	排队等待：漏桶算法
	热点数据限流：令牌桶算法

```

## 21、拓展面试题

```shell
1、sentinel如果进行限流的
	1）、基于sentinel依赖提供的拦截器
	2）、@sentinelresource注解，这个是通过aop实现的前后限流、熔断降级等处理。
2、sentinel默认的限流算法是
	滑动窗口算法
3、sentinel的阈值类型有
	QPS和线程数
4、senttinel的限流规则默认有哪些
	直连、关联、链路
5、sentinel的限流效果
	快速失败、预热、等待排队
6、Sentinel中限流，降级的异常父类是是？
	BlockException
7、sentinel出现降级熔断是，系统底层的异常是？
	DegradeException
8、sentinel的异常处理接口是谁
	BlockExceptionHandler
9、Sentinel中异常处理接口下默认的实现类为
	DefaultBlockExceptionHandler
10、默认的异常规则不满足需求怎么办
	可以自定义，直接或间接实现BlockExceptionHandler
11、Sentinel熔断降级策略有哪些？
	慢调用比例、异常比例、每分钟异常数
12、sentinel常用的系统规则有哪些
	平均响应时间（RT）、QPS、CPU负载、线程数、系统负荷load
```

## 22、限流的方法有哪些

```shell
限流：限流就是对请求的数量进行限制，避免瞬时的大量请求击垮软件系统


#限流的好处，可以应对
1、热点业务带来的突发请求；
2、调用方 bug 导致的突发请求；
3、恶意攻击请求。
因此对于公开的接口最好采取限流措施。

#固定窗口计数器算法
	概念：将时间划分为多个窗口，在每个窗口内有一个请求计数器就加一，如果加速器超过了限制数量，将本窗口内的请求丢弃到下一个时间窗口，计数器重置。
	固定窗口就是时间窗口，规定单位时间处理的请求数量。
缺点：
	无法保证限流速率，无法保证突然激增的流量。

#滑动窗口计数器算法
	概念；将时间划分为多个区间，没个区间内有一次请求就建计数器加一。维持的一个时间窗口，占据多个区间。经过一个区间时间，抛弃最老的区间，纳入最新的一个区间。如果当前窗口内区间请求总和超过了限制数据，窗口请求被丢弃。
	
固定窗口的升级版，将时间以一定的比例分片。划分的分片越多，滑动窗口的滚动越平滑，限流的统计就会越精确。

#漏桶算法
往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。队列来保存请求，定期从队列中拿到请求来执行。（消息队列的削峰\限流的思想）

#令牌桶算法
令牌桶算法也比较简单。和漏桶算法算法一样。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。

#单机限流的工具类
	Google Guava：RateLimiter 基于令牌桶算法，可以应对突发流量。
	Bucket4j 是一个非常不错的基于令牌/漏桶算法的限流库。
	Resilience4j 是一个轻量级的容错组件，其灵感来自于 Hystrix。

#分布式限流
	借助中间件限流：可以借助 Sentinel 或者使用 Redis 来自己实现对应的限流逻辑。
	网关层限流：Spring Cloud Gateway 的分布式限流实现RedisRateLimiter就是基于 Redis+Lua 来实现的，再比如 Spring Cloud Gateway 还可以整合 Sentinel 来做限流。
```

## 23、mysql的三大日志

```shell
mysql日志包括错误日志、查询日志、慢查询日志、事务日志、二进制日志等几大类。
比较重要的属二进制日志：
	binlog（归档日志）、重做日志(redolog)、回滚日志（undolog）
	
#事务日志（redolog）
重做日志(redolog)是innoDB存储引擎独有的，让mysql拥有了崩溃恢复能力。
mysql宕机了，重启时，InnoDB会使用redo log恢复数据，保证数据的持久性。
mysql数据以页为单位，查询数据是一页的数据加载出来，加载处理的数据叫数据也。会放到buffer poll中。
	后续查询操作在buffer poll中找，没有才访问硬盘加载。减少硬盘IO开销，提升性能。
	更新数据，也是如此。buffer pool存在更新数据，直接在buffer poll更新。然后把修改记录到重做日志缓存（redo log buffer）。接着刷盘到redolog日志里。
	刷盘根据策略来进行：
		每条redolog记录包括：表空间号+数据页号+偏移量+修改数据长度+具体修改的数据
	刷盘策略：innodb_flush_log_at_trx_commit 参数
		0：事务提交时不刷盘
		1：事务提交时刷盘（默认值）
		2：事务提交时只把redolog buffer内容写入page cache。
注意：InnoDB存储有一个后台线程，每隔1秒，会把redolog buffer内容写到文件系统缓存page cache，然后调用fsync刷盘。也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘。		
	为0时，如果MySQL宕机可能会有1秒数据的丢失。
	为1时，只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。
    为2时，只要事务提交成功，redo log buffer中内容只写入文件系统缓存（page cache）。宕机可能会有1秒数据的丢失。	
  
#归档日志（binlog）
不管是什么存储引擎，都会产生binlog日志。
MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。binlog会记录所有涉及更新数据的逻辑操作，并且是顺序写。
三种格式：binlog_format参数指定
	statement：记录sql语句原文，存在的问题是时间now()，执行会导致与原库不一致.
	row:看不到详细信息，需要通过mysqlbinlog工具解析。保证数据一致性，通常都是row。
	mixed：混合模式，mysql判断语句是否会引起不一致，是就用row，不会就用statement。
	
写入机制：
	事务执行过程过，把日志写到binlog cache中，事务提交后，把binlog cache写到binlog中。
	
#两阶段提交方案 
	redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。binlog（归档日志）保证了MySQL集群架构的数据一致性。
	在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样。为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。
	redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。使用这个步骤后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。
	
#回滚事务（undolog）
	保证事务的原子性，在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。
	
#总结
	MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。
	MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。
```

## 24、死锁

```shell
多个线程同事被阻塞，它们中的一个或者全部都在等待某个资源被释放。

#产生死锁的条件
1、互斥条件：该资源任意一个时刻只由一个线程占用。
2、请求与保持条件：一个线程请求资源阻塞是，对已获得的资源保持不放。
3、不剥夺条件：线程已获得的资源不能被其他资源强行剥夺，只有自己完毕后才释放资源。
4、循环等待条件：线程之间形成头尾相连的循环等待资源关系。

#预防死锁就是破坏死锁条件
1、请求于保持条件：一次性申请所有资源
2、不剥夺条件：申请不到需要的资源，可以主动释放自己占用的资源。
3、循环等待条件：按序申请，释放反序释放。

# sleep() 方法和 wait() 方法区别和共同点
不同：
	sleep方法没有释放锁，wait释放了锁
	sleep通常用于暂停，wait用于交互/通信
	sleep执行后，自动苏醒。wait需要别的线程唤醒，wait(long)可以自动苏醒
	sleep是Thread类，wait是object类
相同：
	两者都暂停了线程的运行
```

## 25、读写分离和分库分表

```shell
#垂直拆分和水平拆分
	垂直拆分：根据业务的纬度，将原本的一个库（表）拆分为多个库（表），每个库（表）与原有的结构不同。
	水平拆分：根据分片算法，将一个库（表）拆分为多个库（表），每个库（表）依旧保留原有的结构。
	两种拆分可能会同时存在，通常先进行垂直拆分，是单体应用形成多个微服务结构，在微服务中再进行水平库（表）拆分。

#三个阶段
单库单表、单库多表、多库多表

#读写分离
	读写分离就是为了将数据库的读写操作分散到不同的数据节点上。这样可以提升读写性能。
	一般采用一主多从，一台主数据库负责写，其他的从数据库负责读，主库和从库之间会进行数据同步，保证数据的准确性。

#读写分离的问题
	主库和从库数据同步存在延迟。
	1、强制将读请求路由到主库处理，必须获取最新数据的读请求都交个主库处理。
	2、延迟读取，对于新修改的数据。根据同步延迟时间，设置延迟读取。
#如何实现读写分离
	1、部署多台数据库，选择其中一台作为主数据库，其他的一台或者多台作为从数据库。
	2、保证主数据库和从数据库之间的数据实时同步，主从复制
	3、系统将写请求交给主数据库处理，读请求交给从数据库处理。
	
#实现方式
	1、代理方式
		应用和数据中间加代理层。数据请求交给代理层处理，代理层分发读写请求。
		例如：MyCat
	2、组件方式
		引入第三方组件来实现读写请求，目前使用比较多。
		例如；sharding-jdbc
#主从复制原理
	mysql的binlog日志文件主要记录了mysql数据库中数据的所有变化（数据库的DDL（数据库定义语言）和DML（数据库操作语言）语句）。根据主库的binlog日志同步数据到从库中。
	1、主库将数据库中的数据变化写入到binlog
	2、从库连接主库
	3、从库会创建一个I/O线程向主库请求更新的binlog
	4、主库会创建一个binlog dump线程来发送binlog，从库的I/O线程负责接收
	5、从库的I/O线程将接收的binlog写入到relay log中
	6、从库的sql线程线程夫妻relay log同步数据本地。

#分库分表
	分库就是将数据库中的数据分散到不同的数据库中。
	分表就是对单表的数据进行拆分，可以是垂直拆分、也可以是水平拆分
	垂直拆分：将数据表项列的拆分，拆分列比较多的表为多个表
	水平拆分：水平拆分是将数据表行的拆分，把行比较多的表拆分为多张表。
	
#为什么需要分库分表
	单表的数据达到千万级以上，数据库读写速度比较缓慢。
	数据库的数据占用空间越来越大，备份时间越来越长。
	应用的并发量太大（分库）
#分库分表的问题
	join操作：数据库的表分布在不同的数据库中，无法使用join。需要手动查找后封装。
	事务问题：单个操作修改多个数据库数据，数据库自带的事务无法满足。
	分布式的ID：数据库自增主键无法满足主键唯一。
	...
#分库分表的解决方案
	例：ShardingSphere 支持读写分离和分库分表，还提供分布式事务、数据库治理等功能。

#分库分表后，数据怎么迁移
	双写、或者停机维护或者借助同步工具Canal
```

## 26、负载均衡

```shell
#负载均衡
负载均衡系统通常用于将任务比如用户请求处理分配到多个服务器处理以提高网站、应用或者数据库的性能和可靠性。

#常见的负责均衡方案
1、DNS（域名系统）负载均衡：地理基本的均衡
2、硬件负载均衡器：F5负载均衡器
3、软件负责均衡：nginx

#常见的负载均衡算法
1、轮询法
2、随机法
3、源地址哈希法
4、加权轮询法
5、加权随机法
6、最小连接数法
```

## 27、分布式锁和分布式事务

```shell
#分布式事务 强一致行、弱一致性、最终一致性
https://mp.weixin.qq.com/s/BaCRdeLn8VDmAXITAz6rSg
一、两阶段提交（2PC）
	将分布事务提交拆分为2个阶段，prepare和commit/rollback
	在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景。两阶段提交这种解决方案属于牺牲了一部分可用性来换取的一致性。
	
二、补偿事务（TCC）
	针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。TCC模型对业务的侵入强。
	
三、本地消息表（异步确保）
	业界使用最多，核心思想是将分布式事务拆分成本地事务进行处理。
	生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。
四、saga
	则是一种基于补偿的消息驱动的用于解决,确保系统高可用的前提下尽量确保数据的一致性。
	服务器A的事务先执行，如果执行顺利，那么事务A就先行提交；如果提交成功，那么就开始执行事务B，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，那事务B本身需要回滚，这时因为事务A已经提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。
	
五、事务MQ
	将两个事务分支通过MQ进行异步解耦，类型两阶段提交。RocketMQ支持。

六、尽最大努力通知
	借助MQ消息系统来进行事务控制，定时校对，实现数据一直性。
	如支付宝、微信的支付回调接口方式，不断回调直至成功，或直至调用次数衰减至失败状态。
	
#分布式锁
https://mp.weixin.qq.com/s/ioUIbKi5i3K-lFg0OpvT1w
三个属性
	互斥：同一时刻只能有一个客户端持有锁
	避免死锁：锁需要存活时间(TTL time to live)，更严格的情况需要自增ID阻断冲突请求。
	容错：具有一点容错性，避免点点故障
		锁服务自身具有容错性：zookeeper、etcd
		在多个独立的锁服务获取多把锁redlock
两大类
	自旋类：
		自旋类包括基于数据库的实现和基于 Redis 的实现，不停反复请求锁服务查看是否能够获取到锁。
	监听类：
		基于 ZooKeeper 或 etcd 实现的分布式锁，这类实现客户端只需监听(watch) 某个 key，当锁可用时锁服务会通知客户端，无需客户端不停请求锁服务。
```

## 28、高可用设计

```shell
1、集群，减少单点故障
2、限流
3、超时或者重试机制
4、熔断机制
5、异步调用
6、使用缓存
7、容灾备份：备份数据，容灾是异地建立两个完全相同的系统，避免某个服务挂掉，服务不可用。
...
```

## 29、网关

```shell
#Spring Cloud Gateway
Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。
Spring Cloud Gateway 通过过滤器来处理请求。
```

## 30、分布式ID

```shell
1、基于数据库号段模式

2、UUID

3、雪花算法

4、Leaf（美团）：世界上没有两片相同的树叶，Leaf 提供了 号段模式 和 Snowflake(雪花算法) 这两种模式来生成分布式 ID
```

## 31、hash的长度为什么是2的幂次方

```shell
hash值的范围太大，散列值是不能直接拿来用的，太占用内存。用之前先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。数组下标的计算方法是“ (n - 1) & hash”），且运算符采用二进制运算符，比%运算符运算效率更高。
```

## 32、浏览器输入URL发生了什么？

```shell
1、DNS解析
2、TCP连接
3、发送HTTP请求
4、服务器处理请求并返回HTTP报文
5、浏览器解析渲染页面
6、连接结束
```

# mybatis

## 1、什么是mybatis

```shell
mybatis 是一个半持久化框架，开发时不需要我们去处理加载驱动、创建连接、创建statement等繁杂的过程。
```

## 2、Mybatis是半ORM框架?/与Hibernate有哪些不同?

```shell
Hibernate为完整的ORM框架，Mybatis为半ORM框架。
Mybatis程序员直接编写原生sql，可严格控制sql执行性能，灵活度高。
```

## 3、**#{}和${}的区别?**

```shell
${}是properties文件中的变量占位符，属于静态文本替换.

#{}是sql的参数占位符，Mybatis会将sql中的#{}替换为?号，在 sql 执行前会使用 
```

## 4、xml映射文件中，除了常见的标签还有什么

```shell
<resultMap> 、 <parameterMap> 、 <sql> 、 <include> 、 <selectKey> trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中 <sql> 为 sql 片段标签，通过 <include> 标签引入 sql 片段， <selectKey> 为不支持自增的主键生成策略标签。
```

## 5、实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？

```shell
Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。 

Mapper 接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个 MappedStatement ，举例： com.mybatis3.mappers. StudentDao.findStudentById ，可以唯一找到 namespace 为 com.mybatis3.mappers. StudentDao 下面 id = findStudentById 的 MappedStatement 。在 MyBatis 中，每一个 <select> 、 <insert> 、 <update> 、 <delete> 标签，都会被解析为一个 MappedStatement 对象。

Dao 接口的工作原理是 JDK 动态代理，MyBatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 MappedStatement 所代表的 sql，然后将 sql 执行结果返回。
```

## 6、MyBatis 是如何进行分页的？分页插件的原理是什么？

```shell
MyBatis 使用 RowBounds 对象进行分页
```

## 7、MyBatis 是否支持延迟加载？如果支持，它的实现原理是什么？

```shell
MyBatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 MyBatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。

使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，发现有拦截值后，调用事先保存关联的对象sql，查询。
```

# 面试技巧

## 项目经验

社招面试项目很重要，不光是你项目本身的技术复杂度，还有业务复杂度，你本身在项目中担任的什么角色，遇到过什么问题，瓶颈在哪，怎么解决的，这几个问题是非常重要的，很多公司到最后基本上都是围绕着你的项目在问，给面试官讲明白你的项目是必须具备的能力 

 **总结下社招面试问项目最主要的问题套路：** 

 1.你项目为什么这么设计，你这样设计有什么好处，解决了什么问题，会产生什么问题，还有什么可以优化的 

 2.这么设计有什么瓶颈吗，遇到了什么问题，有什么改善的方案 

 3.项目遇到的难点，技术挑战，你是怎么解决的，为什么用这种方式解决，还有更好的方式么 

 4.根据你简历上提到的具体功能去扣细节

## 面试技巧

1.面试得自信且谦虚，声音自信，面试表现谦虚，得给面试官一种你啥都会，很稳的感觉(实际内心很慌），然后语言表达流畅，吐字清晰，回答问题也要有逻辑性，不能支支吾吾半天说不明白，面试官都听不懂，这就很尴尬了，这个可以自己多练习一下 

 2.面试本质是一个自我优势展示的过程，不要让面试官问一句自己回答一句，主动抛出一些可能的点让面试官来主动问你，还有就是不会的问题就说不会，这个没关系的，千万别瞎说 

 3.不要眼高手低，不少小伙伴看面经觉得自己啥都会，但是会与面试过程中能清晰有层次的说出来是两回事，费曼学习法可以了解一下，举个例子：比如sychronized的原理，能不能说出点面试官眼前一亮的东西，这还是不容易的，其实面试主要是证明你比别人更有技术的深度，广度，不然都是背八股文，那面试官看不出你有什么不一样的，这个面试过的概率就大大降低了 

 个人建议，面试没准备好，不要随便面试，一些大厂都会有面试评价记录，太多差评影响以后的面试，同时面完之后要多总结，复盘，整理知识点，查漏补缺

## 面试最后

**面试结束时问面试官什么问题**

我一般会问：

- 我面试的岗位的具体工作是什么
- 使用的技术栈有哪些

**面试总结** 

 阿里的面试更倾向于实用性，基本是从各种场景出发，来给你一个场景，让你来解决实际的问题，那么在解决问题的过程中，对于各种知识的应用就是亮点了 

 头条更看重计算机基础，算法，以及对各种中间件的了解 

 面试也有不少的运气成分的，毕竟每个面试官的侧重点可能不一样，大家放平心态就好

**学习建议**

学习要形成自己的知识体系，不要天天盯着别人的面经做碎片化学习，面经只是辅助作用，查漏补缺的，一旦你的知识体系有了，很多问题都能举一反三，这时候面试就很稳了

